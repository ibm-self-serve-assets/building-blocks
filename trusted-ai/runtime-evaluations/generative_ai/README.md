# Runtime Prompt Evaluations with IBM WatsonX Governance

This repository contains **Runtime Evaluations** for **Prompt Governance** in **Large Language Models (LLMs)** using the **IBM WatsonX Governance SDK**. These evaluations ensure that prompts and responses generated by LLMs are compliant, transparent, and fair during their deployment in real-time.

---

## Technology Stack

- **Python 3.10+**
- **IBM watsonx.governance SDK**: for model governance, prompt evaluations, and monitoring.
- **Jupyter Notebooks**: for interactive development and experimentation.
- **python-dotenv**: for managing environment configurations.
- **IBM Cloud SDK**: for authentication with IBM Cloud services.

---

## Prerequisites

Before you can start working with Runtime Evaluations for Prompt Governance, make sure you have the following:

### 1. **IBM WatsonX Governance Service Instance**
   - Create an instance of the **IBM WatsonX Governance** service via the [IBM Cloud Catalog](https://cloud.ibm.com/catalog) to access the necessary tools and APIs for prompt governance.

### 2. **IBM Cloud API Key**
   - Generate an **API Key** for authenticating with IBM Cloud using the [IBM Cloud API Key Generator](https://cloud.ibm.com/docs/account?topic=account-userapikey).

### 3. **Access to IBM WatsonX Governance Service**
   - Ensure you have appropriate access to the **watsonx.governance** service instance to monitor prompts, track model performance, and run evaluations.

---

## Project Struture

```
.
├── README.md
├── generative_ai
│   ├── LICENSE
│   ├── README.md
│   ├── SETUP.md
│   ├── app.py
│   ├── notebooks
│   │   ├── 00-runtime-evaluation-realtime
│   │   │   ├── Manual_Prompt_Evaluation_for_Production.ipynb
│   │   │   └── README.md
│   │   ├── 01-runtime-evaluation-scheduled
│   │   │   └── Automated_Prompt_Evaluation_for_Production.ipynb
│   │   ├── 02-custom-metrics-monitoring-deployment
│   │   │   └── Custom_Metrics_Monitoring_and_Deployment.ipynb
│   │   ├── README.md
│   │   └── assets
│   │       ├── RAG_data.csv
│   │       └── summarisation.csv
│   └── requirements.txt
└── traditional_ai
    └── notebooks
        ├── Custom_Monitors_and_Custom_Metrics_Deployment.ipynb
        ├── Fairness_Monitoring_with_Indirect_Bias_Mechanism.ipynb
        └── Model_Risk_Management.ipynb


```

---
