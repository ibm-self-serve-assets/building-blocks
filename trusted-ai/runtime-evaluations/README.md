# Runtime Monitoring


Monitoring AI models after deployment is essential to ensuring they behave safely and reliably in real-world conditions. Runtime monitoring generally consists of two key AI evaluation categories. 

**(1) Real-Time Guardrails:** 

The first focuses on maintaining control over unwanted or unsafe model behavior, such as instantly detecting and blocking jailbreak attempts, harmful outputs, or other forms of misuse, by implementing robust real-time AI guardrails. 

**(2) Continuous Monitoring:** 

The second focuses on tracking a range of metrics over time to detect issues like model's performance drift, which may arise as user input patterns, data distributions, or usage contexts evolve. Together, these continuous monitoring practices help teams identify deviations early, preserve model quality, and maintain trust in AI-driven systems.
  

<img src="real-time-guardrails/images/Guardrails vs monitoring.png" 
     alt="Guardrails vs monitoring" 
     style="width: 80%;"/>
