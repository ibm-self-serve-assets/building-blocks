{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1b3ac2",
   "metadata": {},
   "source": [
    "# LLM Pentest Execution Workflow Using REST API\n",
    "\n",
    "This notebook serves as a regression test and tutorial for conducting penetration tests using our API. We'll walk through the entire process, from setting up the test to interpreting results and implementing security measures.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Getting Started\n",
    "Selecting an existing endpoint\n",
    "Creating a new endpoint\n",
    "2. Understanding and Working with Templates\n",
    "What is a template?\n",
    "Selecting an existing template\n",
    "Creating a new template\n",
    "3. Initiating a Penetration Test\n",
    "Starting a one-time test and polling for results\n",
    "Setting up a scheduled test and polling results\n",
    "4. Generating and Downloading Reports\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e17cb6",
   "metadata": {},
   "source": [
    "## 1. Connecting to the API\n",
    "Before making API calls, need to set up your API connection. Our API uses the Bearer authentication scheme with a JWT token. Follow these steps:\n",
    "\n",
    "1. Create an API key in the user interface in the Admin Console, ensuring it has the necessary roles for penetration testing.\n",
    "2. Use your API key to obtain a JWT token by calling the v1/auth/issue-jwt-token API endpoint.\n",
    "3. Use the obtained JWT token for all subsequent API requests.\n",
    "Here's how to get your JWT token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7214c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Set up API URL and API key\n",
    "API_URL = os.environ.get(\n",
    "    \"API_URL\"\n",
    ")  # Replace with the actual base URL of your AllTrue tenant\n",
    "API_KEY = os.environ.get(\"API_KEY\")  # Set your API key as an environment variable\n",
    "CUSTOMER_ID = os.environ.get(\"CUSTOMER_ID\")  # Replace with your actual customer ID\n",
    "\n",
    "\n",
    "def get_jwt_token(api_key):\n",
    "    endpoint = f\"{API_URL}/v1/auth/issue-jwt-token\"\n",
    "    headers = {\"X-API-Key\": f\"{api_key}\"}\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "\n",
    "# Get the JWT token\n",
    "JWT_TOKEN = get_jwt_token(API_KEY)\n",
    "print(\"JWT token obtained successfully.\")\n",
    "\n",
    "\n",
    "# Function to make API requests\n",
    "def make_api_request(endpoint, token: str, method=\"GET\", data=None):\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "    url = f\"{API_URL}{endpoint}\"\n",
    "\n",
    "    response = requests.request(method, url, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a3ed9",
   "metadata": {},
   "source": [
    "## Testing Your Connection\n",
    "\n",
    "Now that you have obtained your JWT token, you can test your connection by making a request to the /auth/verify-connection endpoint. This will confirm that your token is valid and that you can successfully communicate with the API.\n",
    "\n",
    "The /verify-connection endpoint is a simple endpoint that returns a success message if the connection is valid. If successful, you should see a message confirming the connection and the expiration time of your token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def test_connection():\n",
    "    try:\n",
    "        response = make_api_request(\"/verify-connection\", token=JWT_TOKEN)\n",
    "        print(\"Connection verified successfully:\")\n",
    "        print(json.dumps(response, indent=2))\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error verifying connection: {e}\")\n",
    "\n",
    "\n",
    "test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5939b68a",
   "metadata": {},
   "source": [
    "## Starting a Penetration Test\n",
    "\n",
    "The process of initiating a penetration test using our API involves several key steps:\n",
    "\n",
    "**1. Select or Create an LLM Endpoint:**\n",
    "\n",
    "Choose an existing LLM endpoint to test, or\n",
    "Create a new endpoint for testing\n",
    "\n",
    "**2. Create a Test Template:**\n",
    "\n",
    "A test template is a predefined set of test categories to run\n",
    "Templates are reusable across different endpoints, saving time and ensuring consistency\n",
    "You can customize templates to focus on specific security aspects or to meet particular compliance requirements\n",
    "\n",
    "**3. Initiate the Penetration Test:**\n",
    "\n",
    "Run a one-time test, or\n",
    "Set up a scheduled test for regular security checks\n",
    "\n",
    "Let's dive into each of these steps in detail.\n",
    "\n",
    "## 2. Selecting or Creating an LLM Endpoint\n",
    "\n",
    "Before we can start a penetration test, we need to identify the target - in this case, an LLM endpoint. You have two options:\n",
    "\n",
    "1. Select an existing endpoint from your account\n",
    "2. Create a new endpoint specifically for testing\n",
    "\n",
    "Let's explore both options:\n",
    "\n",
    "### Creating a New LLM Endpoint\n",
    "\n",
    "If you don't have an existing endpoint or want to create a new one specifically for testing, you can use the API to create a new LLM endpoint. To create a llm endpoint, you can use the /v1/inventory/customer/{customer_id}/resources/llm-endpoint endpoint.\n",
    "\n",
    "The body of the request should include the following parameters:\n",
    "\n",
    "- resource_type: The type of llm endpoint, detailed below. For example: OpenAIEndpoint.\n",
    "- display_name: (optional) A human-readable name for the endpoint.\n",
    "- project_ids: (optional) A list of project IDs to put the endpoint resource in.\n",
    "- resource_data: A dictionary of key-value pairs that represent the configuration of the endpoint. The keys and values depend on the resource_type.\n",
    "\n",
    "Below are examples of how to add resources of different types:\n",
    "\n",
    "#### Adding an OpenAI Compatible Endpoint\n",
    "\n",
    "OpenAI Compatible Endpoints are endpoints that follow the same signature as OpenAI's v1/chat/completions endpoints. Use this resource type if you want to register and pentest an OpenAI endpoint, or an endpoint that has the same input/output structure.\n",
    "\n",
    "When registering an OpenAI endpoint, you must provide either an API key or an endpoint-identifier which are used to uniquely identify the resource. If you provide an API key, AllTrue will use the API key to make requests when running a pentest by default. If you would like to use a different API key for pentest, you can override this when initiating a pentest or by setting the pentest_connection_details field in the resource data. Note that you must set the api key in the resource or pentest_connection_details in order to execute pentests.\n",
    "\n",
    "Here's an example of the resource_data for an OpenAI endpoint with all optional fields set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"provider\": \"SomeCompany\",  // Optional. Defaults to \"OpenAI\" \n",
    "    \"base_url\": \"https://api.yourprovider\" , // Optional. Defaults to OpenAI's base URL\n",
    "    \"api_key\": \"your-api-key-here\",  // Optional. The API key to use for making requests\n",
    "    \"endpoint_identifier\": \"your-endpoint-identifier\",  // Optional. The endpoint identifier to use for making requests\n",
    "    \"pentest_connection_details\": {\n",
    "      \"pentest_url\": \"https://api.yourprovider.com/v1\", // Optional. The URL to use for making requests during a pentest\n",
    "       \"pentest_api_key\": \"your-pentest-api-key\", // Optional. The API key to use for making requests during a pentest\n",
    "      \"model\": \"gpt-4o\"  // Optional. The model to use for making requests during a pentest. Defaults to \"gpt-3.5-turbo\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244947a",
   "metadata": {},
   "source": [
    "Here is an example of how to create a new OpenAI compatible endpoint accepting all the defaults - i.e using the same API key for pentest as for registration and calling OpenAI's base URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")  # Replace with your actual OpenAI API key\n",
    "\n",
    "\n",
    "def create_llm_endpoint(customer_id, token, resource_data):\n",
    "    endpoint = f\"/v1/inventory/customer/{customer_id}/resources/llm-endpoint\"\n",
    "    data = {\n",
    "        \"resource_type\": \"OpenAIEndpoint\",\n",
    "        \"display_name\": \"My OpenAI Endpoint\",\n",
    "        \"resource_data\": resource_data,\n",
    "    }\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=data)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Create a new OpenAI endpoint\n",
    "openai_endpoint_data = {\n",
    "    \"api_key\": OPENAI_API_KEY,\n",
    "    \"endpoint_identifier\": \"openai-endpoint-for-pentest-tutorial\",\n",
    "}\n",
    "\n",
    "new_openai_endpoint = create_llm_endpoint(\n",
    "    customer_id=CUSTOMER_ID, token=JWT_TOKEN, resource_data=openai_endpoint_data\n",
    ")\n",
    "new_openai_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae920776",
   "metadata": {},
   "source": [
    "### Adding a Custom REST API Endpoint\n",
    "\n",
    "Sometimes you need to fully specify a custom endpoint that doesn't conform to any standard API structure. This is where custom REST API endpoints come in handy. With custom endpoints, you have complete control over specifying the request and response formats, allowing you to integrate with any LLM API, regardless of its structure.\n",
    "\n",
    "When creating a custom REST API endpoint, you must fully specify how the TRiSM Hub should call your API during a pentest in the pentest_connection_details field. This includes providing the URL, headers, request body, and expected response format.\n",
    "\n",
    "- resource_type: The type of llm endpoint, detailed below. For example: CustomLlmEndpoint.\n",
    "- display_name: (optional) A human-readable name for the endpoint.\n",
    "- project_ids: (optional) A list of project IDs to put the endpoint resource in.\n",
    "- pentest_connection_details:\n",
    "    - pentest_url: The full URL of your API endpoint.\n",
    "    - headers: A dictionary of headers to send with the request, including any necessary authentication.\n",
    "    - body: The request body, which must include the placeholder <<PROMPT>> where the actual prompt will be inserted.\n",
    "    - method: The HTTP method to use, either \"POST\" or \"PUT\".\n",
    "    - response_type: The expected response format, either \"json\", \"text\", or \"ndjson\".\n",
    "        - json: The response is expected to be in JSON format.\n",
    "        - text: The response is expected to be plain text.\n",
    "        - ndjson: The response is expected to be newline-delimited JSON.\n",
    "    - response_jsonpaths: A list of JSONPath expressions to extract the response from the API output. All matches of these expressions will be concatenated together to form the response.\n",
    "    - response_error_values: (Optional) A list of values which when found in the result will be considered an error. This is useful if your API returns a successful code even when there is an error.\n",
    "    - customer_scripts: (Optional) A list of scripts that should be executed for particular endpoint. These scripts are **customer specific** - meaning that an AllTrue engineer will need to write them for you. These should be used only when your API cannot be called directly with a fixed set of headers. Please reach out to AllTrue if you think you need a custom implementation and we will be happy to help.\n",
    "\n",
    "As an example, here is how we would add an OpenAI Endpoint using this resource type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")  # Replace with your actual OpenAI API key\n",
    "\n",
    "\n",
    "def create_custom_api_endpoint(customer_id, token):\n",
    "    endpoint = f\"/v1/inventory/customer/{customer_id}/resources/llm-endpoint\"\n",
    "    data = {\n",
    "        \"resource_type\": \"CustomLlmEndpoint\",\n",
    "        \"display_name\": \"My Custom API Endpoint\",\n",
    "        \"resource_data\": {\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "            \"endpoint_identifier\": \"custom-endpoint-for-pentest-tutorial\",\n",
    "            \"pentest_connection_details\": {\n",
    "                \"pentest_url\": \"https://api.openai.com/v1/chat/completions\",\n",
    "                \"headers\": {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\"},\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": \"<<PROMPT>>\"},\n",
    "                    ],\n",
    "                },\n",
    "                \"method\": \"POST\",\n",
    "                \"response_type\": \"json\",\n",
    "                \"response_jsonpaths\": [\"$.choices[0].text\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=data)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Create a new custom API endpoint\n",
    "new_custom_api_endpoint = create_custom_api_endpoint(\n",
    "    customer_id=CUSTOMER_ID, token=JWT_TOKEN\n",
    ")\n",
    "new_custom_api_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3b34b",
   "metadata": {},
   "source": [
    "### Selecting an Existing LLM Endpoint\n",
    "\n",
    "To select an existing LLM endpoint, we first need to retrieve a list of all available endpoints in your account. We can do this using the /v1/inventory/customer/{customer_id}/resources API endpoint.\n",
    "\n",
    "Here's how to list your existing LLM endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_endpoints(customer_id, token):\n",
    "    endpoint = (\n",
    "        f\"/v1/inventory/customer/{customer_id}/resources?resource_category=llm_endpoint\"\n",
    "    )\n",
    "    response = make_api_request(endpoint, token)\n",
    "    return response\n",
    "\n",
    "\n",
    "endpoints = list_endpoints(customer_id=CUSTOMER_ID, token=JWT_TOKEN)\n",
    "next(\n",
    "    endpoint\n",
    "    for endpoint in endpoints[\"resources\"]\n",
    "    if endpoint[\"resource_display_name\"]\n",
    "    == \"Custom LLM Endpoint (custom-endpoint-for-pentest-tutorial)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2376614",
   "metadata": {},
   "source": [
    "## 3. Understanding and Working with Templates\n",
    "\n",
    "Templates are predefined sets of test categories and configurations used to conduct penetration tests. They allow you to standardize your testing process, ensure consistency across multiple endpoints, and save time by reusing common test configurations.\n",
    "\n",
    "### What is a template?\n",
    "\n",
    "A Pentest template is a set of test categories to run on an endpoint. Each category includes a set of test prompts testing for a specific type of security vulnerability.\n",
    "\n",
    "Templates are created and given names, and are then used to run tests on endpoints. When you run a test, you can specify which template to use. This allows you to reuse the same set of test categories across multiple endpoints, ensuring consistency in your testing process.\n",
    "\n",
    "### Creating a new template\n",
    "\n",
    "To create a new template, you can use the POST /v1/llm-pentest/scan_templates endpoint. The body of the request should include the following parameters:\n",
    "\n",
    "- name: A human-readable name for the template.\n",
    "- pentest_category_ids: The list of test categories to include in the template. Each category is identified by its ID.\n",
    "- customer_id: Your customer ID.\n",
    "\n",
    "Note that either pentest_category_ids or pentest_categories should be provided.\n",
    "\n",
    "To see the list of available test categories, you can use the /v1/llm-pentest/categories endpoint. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_templates(token):\n",
    "    endpoint = f\"/v1/llm-pentest/categories\"\n",
    "    response = make_api_request(endpoint, token)\n",
    "    return response\n",
    "\n",
    "\n",
    "# List available templates\n",
    "templates = list_templates(token=JWT_TOKEN)\n",
    "# show the first two category\n",
    "print(json.dumps(templates[\"llm_pentest_categories\"][:2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb292e13",
   "metadata": {},
   "source": [
    "Once you have the list of categories you want to include in your template, you can create a new template using the POST /v1/inventory/customer/{customer_id}/resources/pentest-template endpoint. Here's an example of how to create a new template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f077759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_template(customer_id, token, template_data):\n",
    "    endpoint = f\"/v1/llm-pentest/scan_templates\"\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=template_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Example template data\n",
    "new_template_data = {\n",
    "    \"name\": \"Template for LLM Pentest Tutorial\",\n",
    "    \"pentest_category_ids\": [\n",
    "        \"input_denial_of_wallet_attack\",\n",
    "        \"renellm\",\n",
    "    ],\n",
    "    \"customer_id\": CUSTOMER_ID,\n",
    "}\n",
    "\n",
    "\n",
    "# Create a new template\n",
    "new_template = create_template(\n",
    "    customer_id=CUSTOMER_ID, token=JWT_TOKEN, template_data=new_template_data\n",
    ")\n",
    "new_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7feda11",
   "metadata": {},
   "source": [
    "### Selecting an Existing Template\n",
    "\n",
    "To select an existing template, you can use the /v1/llm-pentest/scan_templates endpoint to retrieve a list of all available templates in your account. Here's how to list your existing templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_templates(customer_id, token):\n",
    "    endpoint = f\"/v1/llm-pentest/scan_templates?customer_id={customer_id}\"\n",
    "    response = make_api_request(endpoint, token)\n",
    "    return response\n",
    "\n",
    "\n",
    "# List existing templates\n",
    "templates = list_templates(customer_id=CUSTOMER_ID, token=JWT_TOKEN)\n",
    "\n",
    "print(\n",
    "    json.dumps(\n",
    "        next(\n",
    "            template\n",
    "            for template in templates[\"llm_pentest_scan_templates\"]\n",
    "            if template[\"name\"] == \"Template for LLM Pentest Tutorial\"\n",
    "        ),\n",
    "        indent=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06551b37",
   "metadata": {},
   "source": [
    "## 4. Initiating a Penetration Test\n",
    "\n",
    "Now that we have created an LLM endpoint or selected an existing one, have a template ready, we can initiate a penetration test.\n",
    "\n",
    "There are two ways to initiate a penetration test:\n",
    "\n",
    "1. **One-time Test:** Run a single penetration test on the endpoint.\n",
    "2. **Scheduled Test:** Set up a recurring schedule for running penetration tests on the endpoint.\n",
    "\n",
    "### Starting a One-time Test\n",
    "\n",
    "To start a one-time penetration test, you can use the /v1/llm-pentest/scan_templates/{scan_template_id}/start endpoint. The body of the request should include the following parameters:\n",
    "\n",
    "- resource_instance_id: The ID of the LLM endpoint you want to test.\n",
    "- customer_id: Your customer ID.\n",
    "- description: (Optional) A description of the test.\n",
    "- pentest_connection_details: (Optional) Connection details for the pentest. If not provided, the connection details defined when registering the endpoint will be used.\n",
    "\n",
    "Pentests can take some time to run. After starting a test, you will receive a task_id that you can use to poll for the status, and an execution_id you can use to download the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48768c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_one_time_test(scan_template_id, token, test_data):\n",
    "    endpoint = f\"/v1/llm-pentest/scan_templates/{scan_template_id}/start\"\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=test_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Example test data\n",
    "one_time_test_data = {\n",
    "    \"resource_instance_id\": new_openai_endpoint[\"added_resources\"][0][\n",
    "        \"resource_instance_id\"\n",
    "    ],\n",
    "    \"customer_id\": CUSTOMER_ID,\n",
    "    \"description\": \"One-time test for LLM Pentest Tutorial\",\n",
    "}\n",
    "\n",
    "# Start a one-time test\n",
    "one_time_test = start_one_time_test(\n",
    "    scan_template_id=new_template[\"id\"], token=JWT_TOKEN, test_data=one_time_test_data\n",
    ")\n",
    "one_time_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7debb22",
   "metadata": {},
   "source": [
    "You can then get the status of an execution with /customers/{customer_id}/executions/{execution_id}. This will return the status of the execution, including whether it is running, completed, or errored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496661e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_status(customer_id, execution_id, token):\n",
    "    endpoint = f\"/v1/llm-pentest/customers/{customer_id}/executions/{execution_id}\"\n",
    "    response = make_api_request(endpoint, token)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Get the status of the one-time test execution\n",
    "one_time_test_status = get_execution_status(\n",
    "    CUSTOMER_ID, one_time_test[\"llm_pentest_scan_execution_id\"], JWT_TOKEN\n",
    ")\n",
    "print(\"Status:\", one_time_test_status[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e45710",
   "metadata": {},
   "source": [
    "### Setting up a Scheduled Test\n",
    "\n",
    "To set up a recurring schedule for penetration tests, we need to follow a two-step process:\n",
    "\n",
    "1. **Define a Job:** This includes specifying the resource (LLM endpoint) to scan and the template to use.\n",
    "2. **Add a Schedule:** This involves setting the start date, end date, and frequency for the recurring tests.\n",
    "\n",
    "Let's go through each step:\n",
    "\n",
    "#### Step 1: Defining a Job\n",
    "\n",
    "To define a job, we use the /v1/llm-pentest/jobs endpoint. The request body should include:\n",
    "\n",
    "- resource_instance_id: The ID of the LLM endpoint to test.\n",
    "- scan_template_id: The ID of the template to use for the tests.\n",
    "- customer_id: Your customer ID.\n",
    "- description: (Optional) A description of the job.\n",
    "\n",
    "#### Step 2: Adding a Schedule\n",
    "\n",
    "After creating a job, we can add a schedule to it using the /v1/llm-pentest/jobs/{job_id}/schedules endpoint. The request body should include:\n",
    "\n",
    "- start_date: The date and time to start the recurring tests.\n",
    "- end_date: (Optional) The date and time to end the recurring tests.\n",
    "- cron_expression: The cron expression for the schedule. This expression must follow the syntax supported by Amazon EventBridge (https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-scheduled-rule-pattern.html).\n",
    "\n",
    "Let's implement these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e208e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "\n",
    "\n",
    "def create_job(\n",
    "    token: str,\n",
    "    resource_instance_id: str,\n",
    "    scan_template_id: str,\n",
    "    customer_id: str,\n",
    "    description: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    endpoint = f\"/v1/scheduling-jobs/{customer_id}/jobs\"\n",
    "    job_data = {\n",
    "        \"job_type\": \"LLM_PENTEST_SCAN\",\n",
    "        \"enabled\": True,\n",
    "        \"data\": {\n",
    "            \"resource_instance_id\": resource_instance_id,\n",
    "            \"scan_template_id\": scan_template_id,\n",
    "            \"description\": description,\n",
    "        },\n",
    "    }\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=job_data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd61913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job for the endpoint\n",
    "job = create_job(\n",
    "    JWT_TOKEN,\n",
    "    resource_instance_id=new_custom_api_endpoint[\"added_resources\"][0][\n",
    "        \"resource_instance_id\"\n",
    "    ],\n",
    "    scan_template_id=new_template[\"id\"],\n",
    "    customer_id=CUSTOMER_ID,\n",
    "    description=\"Scheduled test for LLM Pentest Tutorial\",\n",
    ")\n",
    "print(json.dumps(job, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a28ee",
   "metadata": {},
   "source": [
    "Now that we have created a job, we can add a schedule to it. Let's add a daily schedule for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_schedule(\n",
    "    token: str,\n",
    "    customer_id: str,\n",
    "    job_id: str,\n",
    "    cron_expression: str,\n",
    "    start_at: str,\n",
    "    end_at: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    endpoint = f\"/v1/scheduling-jobs/{customer_id}/jobs/{job_id}/schedules\"\n",
    "    schedule_data = {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"cron_expression\": cron_expression,\n",
    "        \"start_at\": start_at,\n",
    "        \"end_at\": end_at,\n",
    "    }\n",
    "    response = make_api_request(endpoint, token, method=\"POST\", data=schedule_data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add a daily schedule for the job. Will start immediately, and end in a week.\n",
    "schedule = add_schedule(\n",
    "    JWT_TOKEN,\n",
    "    customer_id=CUSTOMER_ID,\n",
    "    job_id=job[\"job_id\"],\n",
    "    cron_expression=\"0 12 * * ? *\",  # daily at 12 UTC\n",
    "    start_at=datetime.now().isoformat(),\n",
    "    end_at=(datetime.now() + timedelta(days=7)).isoformat(),\n",
    ")\n",
    "\n",
    "print(json.dumps(schedule, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af80c4",
   "metadata": {},
   "source": [
    "## 5. Generating and Downloading Reports\n",
    "\n",
    "Once a penetration test execution is completed, you can generate and download a report of the results. This process involves two steps:\n",
    "\n",
    "1. Generating the report\n",
    "2. Downloading the generated report\n",
    "\n",
    "Let's go through each of these steps in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract status and execution ID from one-time scan\n",
    "execution_id = one_time_test[\"llm_pentest_scan_execution_id\"]\n",
    "status = one_time_test_status[\"status\"]\n",
    "\n",
    "print(f\"Execution ID: {execution_id}\")\n",
    "print(f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40f6a7",
   "metadata": {},
   "source": [
    "### Generating a Report\n",
    "\n",
    "To generate a report for a completed penetration test execution, you can use the /v1/llm-pentest/customers/{customer_id}/executions/generate-report endpoint. This will generate a report for the specified execution ID, and return a pre-signed URL to download the report. This URL remains valid for one hour by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(customer_id, execution_id, token):\n",
    "    endpoint = f\"/v1/llm-pentest/customers/{customer_id}/executions/generate-report\"\n",
    "    response = make_api_request(\n",
    "        endpoint,\n",
    "        token,\n",
    "        method=\"POST\",\n",
    "        data={\"llm_pentest_scan_execution_ids\": [execution_id]},\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fff943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a report for the one-time test execution\n",
    "report = generate_report(CUSTOMER_ID, execution_id, JWT_TOKEN)\n",
    "report_url = report[\"report_url\"]\n",
    "print(\"Download link:\", report_url[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3290351",
   "metadata": {},
   "source": [
    "### Downloading the Report\n",
    "\n",
    "Now that we have generated the report and obtained the download URL, we can proceed to download the report. The URL is pre-signed and typically valid for one hour.\n",
    "\n",
    "To download the report, you can use a simple HTTP GET request to the provided URL. Here's an example of how to download the report using Python's requests library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_report(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# Download the report\n",
    "report_content = download_report(report_url)\n",
    "\n",
    "# Save the report to a file\n",
    "report_filename = \"llm_pentest_report.pdf\"\n",
    "with open(report_filename, \"wb\") as file:\n",
    "    file.write(report_content)\n",
    "\n",
    "print(\"Report downloaded successfully. Saved as:\", report_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71a8c2",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this comprehensive guide, we've walked through the entire process of conducting penetration tests using our API. We covered:\n",
    "\n",
    "1. Setting up the API connection\n",
    "2. Creating and selecting LLM endpoints\n",
    "3. Understanding and working with templates\n",
    "4. Initiating both one-time and scheduled penetration tests\n",
    "5. Generating and downloading reports\n",
    "\n",
    "By following these steps, you can effectively use our API to conduct thorough security assessments of your LLM endpoints. Regular penetration testing is crucial for maintaining the security and integrity of your AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guardrails-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
