{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"IBM Building Blocks \u2013 Documentation","text":"<p>Building Blocks are pre-built, embeddable application capabilities that span AI (Agents, Trust, and Data) and Automation (Build, Observe, and Optimize). They are designed to accelerate innovation by enabling teams to rapidly infuse advanced IBM capabilities directly into their applications.</p> <p>These ready-to-use components simplify the entire lifecycle\u2014development, integration, deployment, and operation\u2014allowing teams to deliver solutions faster and with significantly less complexity. Each Building Block acts as a reference implementation, demonstrating how IBM\u2019s Data &amp; AI and Automation platforms integrate seamlessly within real-world enterprise applications.</p> <p>By adopting these proven and tested patterns, organizations can reduce engineering effort, minimize risk, and achieve a faster time-to-value while maintaining enterprise-grade scalability, security, and governance.</p>"},{"location":"#capability-areas","title":"Capability Areas","text":"<p>AI Core Capabilities</p> <ul> <li> <p>Agents Reusable, enterprise-ready AI building blocks that accelerate agent adoption by enabling the design, orchestration, and deployment of intelligent agents across business workflows.</p> </li> <li> <p>Trust Capabilities that evaluate, tune, and compare prompts and models to optimize outcomes. These building blocks help teams select the most appropriate models for each use case while ensuring transparency, compliance, and responsible AI practices.</p> </li> <li> <p>Data Data for AI Building Blocks accelerate decision-making and improve productivity by enabling intelligent access to enterprise data. They unlock new ways to interact with complex systems\u2014driving smarter, faster, and more efficient operations across the organization.</p> </li> </ul> <p>Automation Core Capabilities</p> <ul> <li> <p>Build Enables secure, automated integration and workflow orchestration across applications and clouds. These building blocks deliver identity and access control, infrastructure automation, and AI-assisted development to support faster, governed deployments.</p> </li> <li> <p>Observe Provides end-to-end visibility across applications and infrastructure, detecting dependencies and performance issues in real time. Advanced network analytics help monitor data flows, optimize connectivity, and ensure reliable performance across hybrid environments.</p> </li> <li> <p>Optimize Delivers continuous monitoring, policy enforcement, and self-healing workflows. These building blocks enable cost-efficient operations, dynamic resource management, and real-time observability to maintain optimal performance, governance, and financial efficiency across hybrid and multicloud environments.</p> </li> </ul> <p></p>"},{"location":"ai-core/","title":"AI Core Capabilities","text":"<p>The AI Core Capabilities consist of three foundational building blocks that accelerate enterprise AI adoption. AI Core Capabilities enable enterprises to design, deploy, and govern AI solutions in a secure, scalable, and reusable manner.</p> <ol> <li> <p>Agents \u2013 Pre-built components for designing, orchestrating, and deploying intelligent agents across business workflows, enabling rapid agent adoption at enterprise scale.</p> </li> <li> <p>Trust \u2013 Tools for evaluating, tuning, and comparing prompts and models to ensure optimal performance, transparency, compliance, and responsible AI practices across use cases.</p> </li> <li> <p>Data \u2013 Capabilities that provide intelligent access to enterprise data, enabling faster decision-making, improved productivity, and more efficient interactions with complex systems.</p> </li> </ol> <p>These building blocks are part of IBM's broader Building Blocks framework\u2014embeddable, production-ready components that reduce engineering effort, minimize risk, and accelerate time-to-value while maintaining enterprise-grade security, scalability, and governance.</p>"},{"location":"ai-core/agents/","title":"Agents \u2013 AI Building Blocks","text":"<p>This framework provides ready-to-use accelerators that make it easier to operationalize AI and GenAI use cases.  Each accelerator addresses a critical capability required to build, integrate, and scale AI-driven applications. These accelerators are designed to integrate seamlessly with enterprise systems, reducing time-to-value for AI projects. By standardizing agent creation, orchestration, and governance, the framework ensures scalability, trust, and efficiency across diverse workloads.</p> <p>The Building Block of Agents includes:</p> <ul> <li>Agent Builder \u2013 Create and deploy agents  </li> <li>Multi-Agent Orchestration \u2013 Coordinate agents, tools, and humans  </li> <li>Agent Gateway \u2013 Connect third-party models and Agents</li> </ul>"},{"location":"ai-core/agents/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Agents building blocks repo</p>"},{"location":"ai-core/agents/#use-cases","title":"Use Cases","text":"<ul> <li>Agent Builder \u2192 Build an HR assistant that automates leave approvals using Workday APIs.  </li> <li>Multi-Agent Orchestration \u2192 Automate a sales pipeline workflow where Salesforce data, Outlook meetings, and Slack updates are coordinated across teams.  </li> <li>Agent Gateway \u2192 Centralized gateway that connects AI agents to multiple LLM providers and external systems with enterprise-grade security and governance.</li> </ul>"},{"location":"ai-core/agents/agent-builder/","title":"Agent Builder","text":"<p>The IBM Agent Builder, powered by the watsonx Orchestrate Agentic Development Kit (ADK), enables developers to rapidly create autonomous task-driven AI agents that interact with enterprise apps, tools, and data.</p>"},{"location":"ai-core/agents/agent-builder/#why-it-matters-for-enterprises","title":"Why It Matters for Enterprises","text":"<ul> <li>Accelerates agent-based automation across business functions</li> <li>Works securely with enterprise data, systems, and workflows</li> <li>Enables scalable digital workforce with observable, auditable AI</li> <li>Reduces custom engineering effort for AI automation</li> </ul>"},{"location":"ai-core/agents/agent-builder/#what-we-do-here","title":"What We Do Here","text":"<ul> <li>Design and assemble agents using Agent Builder + ADK</li> <li>Configure agent behavior including instructions, rules, boundaries, and escalation paths</li> <li>Connect to enterprise capabilities such as tools, apps, data/knowledge sources, and channels</li> <li>Generate deployable assets as versionable artifacts that teams can review, test, and operationalize</li> </ul>"},{"location":"ai-core/agents/agent-builder/#key-features-capabilities","title":"Key Features &amp; Capabilities","text":""},{"location":"ai-core/agents/agent-builder/#agent-development-kit-adk","title":"Agent Development Kit (ADK)","text":"<ul> <li>Packaged as a Python library and CLI tool</li> <li>Enables configuration of agents that run on the watsonx Orchestrate platform</li> <li>Supports integrating agents and tools built on other frameworks</li> </ul>"},{"location":"ai-core/agents/agent-builder/#development-deployment","title":"Development &amp; Deployment","text":"<ul> <li>Developer Edition for local builds and rapid iteration, allowing you to test and refine agents in isolation</li> <li>Once validated, agents can be seamlessly shared and deployed into a production instance of watsonx Orchestrate for team-wide use</li> </ul>"},{"location":"ai-core/agents/agent-builder/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Prompt configuration - Define agent instructions and behavior</li> <li>Tool integration - Connect agents to enterprise systems and APIs</li> <li>Evaluate agents - Test and validate agent performance, accuracy, and behavior</li> <li>Lifecycle management - Version, test, and deploy agents with confidence</li> </ul>"},{"location":"ai-core/agents/agent-builder/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/agents/agent-builder/#business-process-automation","title":"Business Process Automation","text":"<ul> <li>Customer service agents that handle inquiries, route tickets, and escalate complex issues</li> <li>HR automation agents for onboarding, benefits enrollment, and policy queries</li> <li>Finance agents for expense processing, invoice management, and compliance checks</li> </ul>"},{"location":"ai-core/agents/agent-builder/#enterprise-integration","title":"Enterprise Integration","text":"<ul> <li>Data analysis agents that query databases, generate reports, and provide insights</li> <li>Workflow orchestration agents that coordinate tasks across multiple systems</li> <li>IT support agents for troubleshooting, system monitoring, and incident management</li> </ul>"},{"location":"ai-core/agents/agent-builder/#knowledge-work-augmentation","title":"Knowledge Work Augmentation","text":"<ul> <li>Research agents that gather information from multiple sources and synthesize findings</li> <li>Content generation agents for documentation, summaries, and communications</li> <li>Decision support agents that analyze options and provide recommendations</li> </ul>"},{"location":"ai-core/agents/agent-builder/#github-repository","title":"Github Repository","text":"<p>Get started with Agents building blocks</p>"},{"location":"ai-core/agents/ai-gateway/","title":"Agent Gateway","text":"<p>A unified gateway for selecting the right LLM model and securely accessing the right tools and agents across your enterprise.</p>"},{"location":"ai-core/agents/ai-gateway/#why-it-matters-for-enterprises","title":"Why It Matters for Enterprises","text":"<ul> <li>Model compliance and governance - Customers have clearance to only use specific approved models</li> <li>Fine-tuned model support - Customers have a need to use their fine-tuned models for agents</li> <li>Centralized control - Manage all model access, policies, and telemetry from one place</li> <li>Seamless integration - Connect to multiple providers without rewriting applications</li> <li>ContextForge Federates MCP servers, A2A agents, and REST APIs into one governed endpoint</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#supported-llm-providers","title":"Supported LLM Providers","text":"<p>The AI Gateway provides unified access to multiple foundation model providers:</p> <p>Enterprise Platforms: - IBM watsonx.ai - AWS Bedrock - Azure OpenAI</p> <p>Leading AI Providers: - OpenAI - Anthropic - Google (Gemini)</p> <p>Open Source &amp; Specialized: - Mistral - Ollama</p>"},{"location":"ai-core/agents/ai-gateway/#key-features-capabilities","title":"Key Features &amp; Capabilities","text":""},{"location":"ai-core/agents/ai-gateway/#model-gateway","title":"Model Gateway","text":"<ul> <li>Unified API &amp; orchestration layer for multiple foundation models</li> <li>Seamless model switching, routing, and failover without rewriting applications</li> <li>Select the model of choice based on use case requirements</li> <li>Configure models with parameters, model policies, and custom settings</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#enterprise-controls","title":"Enterprise Controls","text":"<ul> <li>Enforce approved models and tools across the organization</li> <li>Central telemetry and observability for all AI traffic</li> <li>Consistent governance across hybrid and multi-cloud deployments</li> <li>Policy enforcement for security, compliance, and cost management</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#advanced-capabilities","title":"Advanced Capabilities","text":"<ul> <li>Unified credential storage - Secure management of API keys and tokens</li> <li>Load balancing - Distribute requests across multiple model instances</li> <li>Failover and retries - Automatic fallback to alternative models</li> <li>Custom API settings - Fine-tune request parameters per model</li> <li>Usage tracking - Monitor consumption, costs, and performance metrics</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#legacy-modernization","title":"Legacy Modernization","text":"<ul> <li>Virtualize existing REST/gRPC services as MCP tools</li> <li>No need to rewrite agents - Integrate legacy systems seamlessly</li> <li>Gradual migration path from traditional APIs to modern AI workflows</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#contextforge","title":"ContextForge","text":"<ul> <li>Federation Single catalog/entry point across multiple MCP and REST services</li> <li>REST-to-MCP Adapter: Virtualize REST APIs as MCP-compliant tools</li> <li>gRPC Translation: Reflection-based discovery and translation to MCP</li> <li>Multi-Transport HTTP, JSON-RPC, WebSocket, SSE, stdio, streamable-HTTP</li> <li>Built-in Security Auth, rate limiting, retries, OAuth token support</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#how-it-works","title":"How It Works","text":"<ol> <li>Select the model - Choose the most suitable model for your agent or use case</li> <li>Configure policies - Set parameters, rate limits, and governance rules</li> <li>Route requests - AI Gateway handles routing, authentication, and failover</li> <li>Monitor and optimize - Track usage, performance, and costs through central telemetry</li> </ol>"},{"location":"ai-core/agents/ai-gateway/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/agents/ai-gateway/#model-compliance-governance","title":"Model Compliance &amp; Governance","text":"<ul> <li>Approved model enforcement - Ensure only certified models are used in production</li> <li>Audit and compliance - Track which models are used for which purposes</li> <li>Regional restrictions - Route to compliant models based on data residency requirements</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#fine-tuned-model-deployment","title":"Fine-Tuned Model Deployment","text":"<ul> <li>Custom model integration - Deploy and manage organization-specific fine-tuned models</li> <li>A/B testing - Compare performance between base and fine-tuned models</li> <li>Gradual rollout - Route percentage of traffic to new model versions</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#multi-provider-model-management","title":"Multi-Provider Model Management","text":"<ul> <li>Cost optimization - Route to most cost-effective model for each task</li> <li>Performance optimization - Select fastest or most accurate model per use case</li> <li>Vendor diversification - Avoid lock-in by supporting multiple providers</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#legacy-system-integration","title":"Legacy System Integration","text":"<ul> <li>API modernization - Expose legacy systems as AI-accessible tools</li> <li>Hybrid workflows - Combine traditional APIs with modern AI agents</li> <li>Incremental transformation - Modernize systems without full rewrites</li> </ul>"},{"location":"ai-core/agents/ai-gateway/#github-repository","title":"Github Repository","text":"<p>Get started with Agents gateway building blocks</p>"},{"location":"ai-core/agents/multi-agent-orchestration/","title":"Multi-Agent Orchestration","text":"<p>Multi-Agent Orchestration enables multiple AI agents to collaborate intelligently to achieve complex enterprise workflows and extend orchestration beyond the platform by integrating external systems through MCP and A2A servers.</p>"},{"location":"ai-core/agents/multi-agent-orchestration/#how-it-works","title":"How It Works","text":"<p>Multi-agent orchestration is a native capability enabling seamless collaboration across AI agents whether they are built on watsonx Orchestrate or with different frameworks and technologies.</p> <ul> <li>Specialized agents - Each agent focuses on a specific domain (e.g., HR, IT, Finance, or Customer Support)</li> <li>Orchestrate runtime - Coordinates agents using context sharing, task routing, and feedback loops</li> <li>External integrations - Connects to external systems via MCP and A2A protocols</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#key-capabilities","title":"Key Capabilities","text":""},{"location":"ai-core/agents/multi-agent-orchestration/#dynamic-task-delegation","title":"Dynamic Task Delegation","text":"<ul> <li>Automatically assigns subtasks to the most capable agent or external system via MCP/A2A integration</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#shared-memory-context","title":"Shared Memory &amp; Context","text":"<ul> <li>Agents and connected systems exchange structured knowledge through a unified memory layer</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#chained-reasoning","title":"Chained Reasoning","text":"<ul> <li>Combines reasoning outputs from multiple agents and external applications to form comprehensive responses or actions</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#goal-driven-execution","title":"Goal-Driven Execution","text":"<ul> <li>End-to-end orchestration from intent detection to action execution across internal and external systems</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#external-system-integration","title":"External System Integration","text":"<ul> <li>MCP Servers - Provide secure gateways, protocol mediation, and event bridging for external systems</li> <li>A2A Servers - Enable workflow extension, transaction orchestration, and scalable integration patterns for third-party applications</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#core-principles","title":"Core Principles","text":""},{"location":"ai-core/agents/multi-agent-orchestration/#interoperability","title":"Interoperability","text":"<ul> <li>Enable agents built on any framework to communicate and collaborate</li> <li>Rely on different agent styles (Default, ReAct, Planner) to handle how complex tasks are resolved</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#standardization","title":"Standardization","text":"<ul> <li>Provide consistent interfaces and protocols for agent interaction leveraging available standards such as MCP and A2A</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#extensibility","title":"Extensibility","text":"<ul> <li>Allow for future expansion and adaptation as agent technologies evolve</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#simplicity","title":"Simplicity","text":"<ul> <li>Make integration as straightforward as possible for business users and developers</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#security","title":"Security","text":"<ul> <li>Ensure secure communication and data handling between agents</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#integration-standards","title":"Integration Standards","text":""},{"location":"ai-core/agents/multi-agent-orchestration/#mcp-model-context-protocol","title":"MCP (Model Context Protocol)","text":"<ul> <li>Open standard enabling secure, two-way connections between data sources and AI-powered tools</li> <li>Supports exposing data through MCP servers or building AI applications that connect to these servers</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#a2a-agent-to-agent","title":"A2A (Agent-to-Agent)","text":"<ul> <li>Open standard enabling AI agents to discover, communicate, and collaborate with one another regardless of underlying technology or platform</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/agents/multi-agent-orchestration/#multi-agent-workflow-orchestration","title":"Multi-Agent Workflow Orchestration","text":"<ul> <li>Cross-functional processes - HR agent coordinates with IT and Finance agents for employee onboarding</li> <li>Complex decision-making - Multiple specialized agents analyze different aspects of a business problem</li> <li>Escalation handling - Agents collaborate to resolve issues, escalating to human experts when needed</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#mcp-server-integration","title":"MCP Server Integration","text":"<ul> <li>Enterprise data access - Agents connect to databases, knowledge bases, and document repositories via MCP servers</li> <li>Real-time data synchronization - MCP servers bridge external systems with agent workflows</li> <li>Secure API gateway - MCP servers provide controlled access to sensitive enterprise systems</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#a2a-agent-collaboration","title":"A2A Agent Collaboration","text":"<ul> <li>Cross-platform agent networks - Agents built on different frameworks collaborate through A2A protocol</li> <li>Distributed agent systems - Agents across multiple departments or organizations work together</li> <li>Third-party agent integration - External AI agents join orchestrated workflows seamlessly</li> </ul>"},{"location":"ai-core/agents/multi-agent-orchestration/#github-repository","title":"Github Repository","text":"<p>Get started with Multi Agents Orcehstration building blocks</p>"},{"location":"ai-core/data/","title":"Data for AI Building Blocks","text":"<p>Data for AI focuses on enabling intelligent data management, transformation, and retrieval for AI applications. It brings together data ingestion, natural language interfaces, retrieval augmented generation, and vector search capabilities to power modern AI-driven solutions.</p> <p>The Building Block of Data for AI includes:</p> <ul> <li>RAG Building Block \u2013 Retrieval Augmented Generation combines vector search with large language models to provide accurate, context-aware responses by retrieving relevant information from knowledge bases.</li> <li>Natural Language to SQL \u2013 Transform natural language questions into accurate SQL queries using AI, enabling non-technical users to access and analyze data through conversational interfaces.</li> <li>Enterprise Intelligent Data Ingestion \u2013 AI-powered data ingestion platform leveraging IBM Event Streams, IBM Cloud Object Storage, and IBM watsonx.data for intelligent enterprise data integration and transformation.</li> <li>Vector Search \u2013 Serverless vector database solutions for AI applications with enterprise-grade reliability, performance, and global distribution capabilities.</li> </ul>"},{"location":"ai-core/data/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Data for AI building blocks repo</p>"},{"location":"ai-core/data/#use-cases","title":"Use Cases","text":"<ul> <li>RAG Building Block \u2192 Organizations leverage RAG to build intelligent chatbots, knowledge assistants, document Q&amp;A systems, customer support automation, and context-aware content generation that combines the power of vector search with LLMs.</li> <li>Natural Language to SQL \u2192 Typical scenarios include business intelligence self-service, data democratization, automated reporting, conversational analytics, and enabling non-technical users to query databases using natural language.</li> <li>Enterprise Intelligent Data Ingestion \u2192 Common use cases involve real-time data streaming, batch data processing, AI-powered data transformation, data quality monitoring, multi-source data integration, and preparing data for AI/ML workloads.</li> <li>Vector Search \u2192 Applications include semantic search, recommendation engines, fraud detection, real-time personalization, similarity matching, and powering RAG systems with efficient vector storage and retrieval.</li> </ul> <p>Together, these building blocks establish a comprehensive data foundation for AI applications, enabling intelligent data access, transformation, and retrieval at enterprise scale.</p>"},{"location":"ai-core/data/intelligent-etl/","title":"Enterprise Intelligent Data Ingestion","text":"<p>AI-powered data ingestion platform leveraging IBM Event Streams, IBM Cloud Object Storage, and IBM watsonx.data for intelligent enterprise data integration and transformation.</p>"},{"location":"ai-core/data/intelligent-etl/#overview","title":"Overview","text":"<p>Enterprise Intelligent Data Ingestion combines streaming, batch, and real-time data processing with AI-powered transformation using IBM watsonx.data, IBM Event Streams, and IBM Cloud Object Storage.</p>"},{"location":"ai-core/data/intelligent-etl/#ibm-watsonxdata-integration","title":"IBM watsonx.data Integration","text":"<p>Leverage IBM's enterprise data lakehouse for scalable data processing.</p> <ul> <li>Open lakehouse architecture</li> <li>Multiple query engines (Presto, Spark)</li> <li>Unified metadata layer</li> <li>Cost-optimized storage</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#ai-powered-transformation","title":"AI-Powered Transformation","text":"<p>Intelligent data transformation using machine learning and AI.</p> <ul> <li>Automated schema mapping</li> <li>Data quality detection</li> <li>Anomaly identification</li> <li>Smart data enrichment</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#enterprise-ready","title":"Enterprise Ready","text":"<p>Production-grade ETL with enterprise security and governance.</p> <ul> <li>Data lineage tracking</li> <li>Role-based access control</li> <li>Audit logging</li> <li>Compliance support</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#key-features","title":"Key Features","text":""},{"location":"ai-core/data/intelligent-etl/#ibm-multi-source-connectivity","title":"IBM Multi-Source Connectivity","text":"<p>Connect to diverse data sources with IBM enterprise connectors and streaming integration.</p> <ul> <li>IBM Db2, PostgreSQL, MySQL, Oracle</li> <li>IBM Cloud Object Storage (COS)</li> <li>IBM Event Streams (Kafka)</li> <li>IBM MQ, APIs, and webhooks</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#confluent-integration","title":"Confluent Integration","text":"<p>Seamless integration with Confluent's data streaming platform for real-time data pipelines.</p>"},{"location":"ai-core/data/intelligent-etl/#confluent-cloud","title":"Confluent Cloud","text":"<p>Enterprise-grade, fully managed Apache Kafka service.</p> <ul> <li>Serverless Kafka clusters</li> <li>Global data distribution</li> <li>Schema Registry integration</li> <li>ksqlDB for stream processing</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#confluent-platform","title":"Confluent Platform","text":"<p>Self-managed Kafka platform for on-premises and hybrid deployments.</p> <ul> <li>Enterprise Kafka distribution</li> <li>Control Center for monitoring</li> <li>Replicator for multi-datacenter</li> <li>Tiered Storage for cost optimization</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#confluent-connectors","title":"Confluent Connectors","text":"<p>Pre-built connectors for seamless data integration.</p> <ul> <li>200+ source and sink connectors</li> <li>IBM watsonx.data connector</li> <li>Cloud storage connectors</li> <li>Database CDC connectors</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#intelligent-transformation","title":"Intelligent Transformation","text":"<p>AI-assisted data transformation and quality improvement.</p> <ul> <li>Auto-detect data types</li> <li>Smart data cleansing</li> <li>Pattern recognition</li> <li>Predictive data mapping</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<p>Real-time monitoring and alerting for data pipelines.</p> <ul> <li>Pipeline health dashboards</li> <li>Data quality metrics</li> <li>Performance monitoring</li> <li>Automated alerting</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/data/intelligent-etl/#data-lake-migration","title":"Data Lake Migration","text":"<p>Migrate legacy data warehouses to modern data lakehouses.</p> <ul> <li>Automated schema conversion</li> <li>Incremental data migration</li> <li>Data validation</li> <li>Zero downtime migration</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#real-time-analytics","title":"Real-time Analytics","text":"<p>Build real-time data pipelines for instant insights.</p> <ul> <li>Streaming data ingestion</li> <li>Real-time transformation</li> <li>Low-latency queries</li> <li>Live dashboards</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#data-quality-management","title":"Data Quality Management","text":"<p>Ensure high-quality data across your organization.</p> <ul> <li>Automated quality checks</li> <li>Anomaly detection</li> <li>Data profiling</li> <li>Quality scorecards</li> </ul>"},{"location":"ai-core/data/intelligent-etl/#aiml-data-preparation","title":"AI/ML Data Preparation","text":"<p>Prepare and transform data for AI and machine learning models.</p> <ul> <li>Feature engineering</li> <li>Data normalization</li> <li>Training data generation</li> <li>Model data versioning</li> </ul>"},{"location":"ai-core/data/nl-to-sql/","title":"NL to SQL Building Block","text":"<p>Transform natural language questions into accurate SQL queries using AI, enabling non-technical users to access data.</p>"},{"location":"ai-core/data/nl-to-sql/#overview","title":"Overview","text":"<p>Convert natural language questions into accurate SQL queries using AI.</p>"},{"location":"ai-core/data/nl-to-sql/#natural-language-input","title":"Natural Language Input","text":"<p>Users ask questions in plain English, no SQL knowledge required.</p> <ul> <li>Conversational interface</li> <li>Context-aware understanding</li> <li>Multi-turn conversations</li> <li>Intent recognition</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#ai-powered-translation","title":"AI-Powered Translation","text":"<p>Advanced LLMs convert questions into optimized SQL queries.</p> <ul> <li>Schema-aware generation</li> <li>Query optimization</li> <li>Syntax validation</li> <li>Error handling</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#instant-results","title":"Instant Results","text":"<p>Execute queries and return results in human-readable format.</p> <ul> <li>Fast query execution</li> <li>Result formatting</li> <li>Data visualization</li> <li>Export capabilities</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#key-features","title":"Key Features","text":""},{"location":"ai-core/data/nl-to-sql/#multi-database-support","title":"Multi-Database Support","text":"<p>Works with all major database systems.</p> <ul> <li>PostgreSQL</li> <li>MySQL</li> <li>SQL Server</li> <li>Oracle</li> <li>SQLite</li> <li>BigQuery</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#schema-understanding","title":"Schema Understanding","text":"<p>Automatically learns your database structure.</p> <ul> <li>Table relationship mapping</li> <li>Column type inference</li> <li>Foreign key detection</li> <li>Index optimization</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#security-validation","title":"Security &amp; Validation","text":"<p>Enterprise-grade security and query validation.</p> <ul> <li>SQL injection prevention</li> <li>Permission checking</li> <li>Query sanitization</li> <li>Audit logging</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#example-queries","title":"Example Queries","text":""},{"location":"ai-core/data/nl-to-sql/#question-what-were-our-total-sales-last-quarter","title":"Question: \"What were our total sales last quarter?\"","text":"<pre><code>SELECT SUM(amount) as total_sales\nFROM sales\nWHERE date &gt;= '2025-10-01'\n  AND date &lt; '2026-01-01'\n</code></pre>"},{"location":"ai-core/data/nl-to-sql/#question-show-me-customers-who-havent-ordered-in-6-months","title":"Question: \"Show me customers who haven't ordered in 6 months\"","text":"<pre><code>SELECT customer_name, last_order_date\nFROM customers\nWHERE last_order_date &lt; CURRENT_DATE - INTERVAL '6 months'\nORDER BY last_order_date DESC\n</code></pre>"},{"location":"ai-core/data/nl-to-sql/#question-which-products-are-low-in-stock","title":"Question: \"Which products are low in stock?\"","text":"<pre><code>SELECT product_name, quantity\nFROM inventory\nWHERE quantity &lt; reorder_level\nORDER BY quantity ASC\n</code></pre>"},{"location":"ai-core/data/nl-to-sql/#question-top-5-products-by-revenue-this-month","title":"Question: \"Top 5 products by revenue this month\"","text":"<pre><code>SELECT product_name, SUM(price * quantity) as revenue\nFROM orders\nWHERE MONTH(order_date) = MONTH(CURRENT_DATE)\nGROUP BY product_name\nORDER BY revenue DESC\nLIMIT 5\n</code></pre>"},{"location":"ai-core/data/nl-to-sql/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/data/nl-to-sql/#business-intelligence","title":"Business Intelligence","text":"<p>Empower business users to query data without SQL knowledge.</p> <ul> <li>Self-service analytics</li> <li>Ad-hoc reporting</li> <li>Dashboard creation</li> <li>Trend analysis</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#customer-support","title":"Customer Support","text":"<p>Enable support teams to quickly access customer data.</p> <ul> <li>Customer lookup</li> <li>Order history</li> <li>Issue tracking</li> <li>Performance metrics</li> </ul>"},{"location":"ai-core/data/nl-to-sql/#data-exploration","title":"Data Exploration","text":"<p>Accelerate data discovery and analysis.</p> <ul> <li>Schema exploration</li> <li>Data profiling</li> <li>Pattern discovery</li> <li>Quality checks</li> </ul>"},{"location":"ai-core/data/rag-building-block/","title":"RAG Building Block","text":"<p>Retrieval Augmented Generation for intelligent AI applications that combine vector search with large language models.</p>"},{"location":"ai-core/data/rag-building-block/#overview","title":"Overview","text":"<p>RAG combines the power of vector search with large language models to provide accurate, context-aware responses.</p>"},{"location":"ai-core/data/rag-building-block/#knowledge-retrieval","title":"Knowledge Retrieval","text":"<p>Retrieve relevant information from your knowledge base using semantic search.</p> <ul> <li>Vector embeddings for semantic understanding</li> <li>Efficient similarity search</li> <li>Context-aware retrieval</li> <li>Multi-source data integration</li> </ul>"},{"location":"ai-core/data/rag-building-block/#llm-generation","title":"LLM Generation","text":"<p>Generate accurate responses using retrieved context and large language models.</p> <ul> <li>OpenAI GPT integration</li> <li>IBM Watsonx support</li> <li>Custom prompt engineering</li> <li>Response validation</li> </ul>"},{"location":"ai-core/data/rag-building-block/#production-ready","title":"Production Ready","text":"<p>Enterprise-grade components ready for production deployment.</p> <ul> <li>Scalable architecture</li> <li>Error handling and logging</li> <li>Performance optimization</li> <li>Security best practices</li> </ul>"},{"location":"ai-core/data/rag-building-block/#key-features","title":"Key Features","text":""},{"location":"ai-core/data/rag-building-block/#vector-database-support","title":"Vector Database Support","text":"<p>Integrate with popular vector databases for efficient storage and retrieval.</p> <ul> <li>DataStax Astra DB</li> <li>OpenSearch</li> </ul>"},{"location":"ai-core/data/rag-building-block/#document-processing","title":"Document Processing","text":"<p>Automated document ingestion and chunking for optimal retrieval.</p> <ul> <li>PDF, DOCX, TXT, EML support</li> <li>Smart chunking strategies</li> <li>Metadata extraction</li> <li>Batch processing</li> </ul>"},{"location":"ai-core/data/rag-building-block/#framework-integration","title":"Framework Integration","text":"<p>Seamless integration with popular AI frameworks.</p> <ul> <li>LangChain compatibility</li> <li>LlamaIndex support</li> <li>Custom pipeline builders</li> <li>API-first design</li> </ul>"},{"location":"ai-core/data/rag-building-block/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/data/rag-building-block/#customer-support","title":"Customer Support","text":"<p>AI-powered chatbots that answer questions using your knowledge base.</p> <ul> <li>24/7 automated support</li> <li>Accurate, context-aware responses</li> <li>Reduced support costs</li> <li>Improved customer satisfaction</li> </ul>"},{"location":"ai-core/data/rag-building-block/#document-qa","title":"Document Q&amp;A","text":"<p>Query large document collections with natural language.</p> <ul> <li>Instant information retrieval</li> <li>Cross-document insights</li> <li>Compliance and legal research</li> <li>Knowledge management</li> </ul>"},{"location":"ai-core/data/rag-building-block/#educational-tools","title":"Educational Tools","text":"<p>Personalized learning assistants and tutoring systems.</p> <ul> <li>Adaptive learning paths</li> <li>Instant explanations</li> <li>Study material generation</li> <li>Assessment support</li> </ul>"},{"location":"ai-core/data/rag-building-block/#research-assistant","title":"Research Assistant","text":"<p>Accelerate research with AI-powered literature review.</p> <ul> <li>Paper summarization</li> <li>Citation discovery</li> <li>Trend analysis</li> <li>Hypothesis generation</li> </ul>"},{"location":"ai-core/data/vector_search/","title":"Vector Search","text":"<p>Enterprise-grade vector database solutions for AI applications with high performance, scalability, and reliability.</p>"},{"location":"ai-core/data/vector_search/#overview","title":"Overview","text":"<p>Vector search enables semantic similarity search for AI applications by storing and querying high-dimensional vector embeddings. This technology powers modern AI applications including RAG systems, recommendation engines, semantic search, and real-time personalization.</p>"},{"location":"ai-core/data/vector_search/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Semantic Search - Find similar items based on meaning, not just keywords</li> <li>High Performance - Sub-millisecond query latency at scale</li> <li>Scalability - Handle millions to billions of vectors</li> <li>Enterprise Ready - Production-grade reliability and security</li> </ul>"},{"location":"ai-core/data/vector_search/#vector-database-solutions","title":"Vector Database Solutions","text":"<p>Our vector search building blocks include enterprise-grade database solutions that provide:</p> <ul> <li>Native vector data types and indexing</li> <li>Approximate nearest neighbor (ANN) search</li> <li>Hybrid search (vector + metadata filtering)</li> <li>Global distribution and high availability</li> <li>Enterprise SLAs and support</li> </ul>"},{"location":"ai-core/data/vector_search/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/data/vector_search/#rag-applications","title":"RAG Applications","text":"<p>Power retrieval augmented generation systems with efficient vector storage and semantic search capabilities.</p>"},{"location":"ai-core/data/vector_search/#recommendation-engines","title":"Recommendation Engines","text":"<p>Build personalized recommendation systems using vector similarity to match user preferences with items.</p>"},{"location":"ai-core/data/vector_search/#semantic-search","title":"Semantic Search","text":"<p>Implement intelligent search that understands meaning and context, going beyond keyword matching.</p>"},{"location":"ai-core/data/vector_search/#fraud-detection","title":"Fraud Detection","text":"<p>Identify anomalous patterns and fraudulent behavior using vector-based similarity detection.</p>"},{"location":"ai-core/data/vector_search/#real-time-personalization","title":"Real-time Personalization","text":"<p>Deliver personalized experiences at scale by matching user behavior vectors with content vectors.</p>"},{"location":"ai-core/data/vector_search/#getting-started","title":"Getting Started","text":"<p>Explore our vector database solutions to find the right fit for your AI application:</p> <ul> <li>DataStax Astra DB - Serverless vector database built on Apache Cassandra with global distribution and enterprise SLAs</li> <li>OpenSearch - Open-source search and analytics engine with native vector search and hybrid search capabilities</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/","title":"DataStax Astra DB","text":"<p>Serverless vector database built on Apache Cassandra for AI applications with enterprise-grade reliability and performance.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#why-datastax-for-partners","title":"Why DataStax for Partners","text":"<p>Build and scale AI applications with enterprise-grade infrastructure.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#enterprise-ready","title":"Enterprise Ready","text":"<p>Production-grade infrastructure with enterprise SLAs and support.</p> <ul> <li>99.99% uptime SLA</li> <li>Multi-region deployment</li> <li>Automated backups</li> <li>24/7 support</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#scalable-performance","title":"Scalable Performance","text":"<p>Handle millions of vectors with sub-millisecond latency.</p> <ul> <li>Horizontal scaling</li> <li>Auto-scaling capabilities</li> <li>Global distribution</li> <li>Low latency queries</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#developer-friendly","title":"Developer Friendly","text":"<p>Simple APIs and comprehensive documentation for rapid development.</p> <ul> <li>RESTful APIs</li> <li>Multiple SDKs</li> <li>Extensive documentation</li> <li>Active community</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#cost-effective","title":"Cost Effective","text":"<p>Generous free tier and flexible pricing for growing businesses.</p> <ul> <li>25GB free tier</li> <li>Pay-as-you-grow pricing</li> <li>No upfront costs</li> <li>Transparent billing</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#common-integration-patterns","title":"Common Integration Patterns","text":"<p>Proven patterns for building AI applications with DataStax.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#rag-applications","title":"RAG Applications","text":"<p>Build retrieval augmented generation systems with vector search.</p> <ul> <li>Document embedding storage</li> <li>Semantic search</li> <li>Context retrieval</li> <li>LLM integration</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#semantic-search","title":"Semantic Search","text":"<p>Implement intelligent search that understands meaning and context.</p> <ul> <li>Vector similarity search</li> <li>Hybrid search</li> <li>Faceted search</li> <li>Real-time indexing</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#recommendation-engines","title":"Recommendation Engines","text":"<p>Power personalized recommendations with vector embeddings.</p> <ul> <li>User preference vectors</li> <li>Item similarity</li> <li>Real-time recommendations</li> <li>A/B testing support</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#real-time-personalization","title":"Real-time Personalization","text":"<p>Deliver personalized experiences at scale.</p> <ul> <li>User behavior tracking</li> <li>Dynamic content</li> <li>Session management</li> <li>Analytics integration</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#fraud-detection","title":"Fraud Detection","text":"<p>Identify anomalies and patterns in real-time.</p> <ul> <li>Pattern recognition</li> <li>Anomaly detection</li> <li>Risk scoring</li> <li>Real-time alerts</li> <li>\u2192 View Fraud Detection App Showcase</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#partner-program-tiers","title":"Partner Program Tiers","text":"<p>Grow your business with our flexible partner program.</p> <p>Partner Program Information</p> <p>Tier details are illustrative. Visit DataStax Partner Program for official requirements and benefits.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#registered-partner","title":"Registered Partner","text":"<p>No minimum requirements</p> <ul> <li>Free tier access</li> <li>Basic support</li> <li>Partner portal access</li> <li>Technical documentation</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#silver-partner","title":"Silver Partner","text":"<p>$10K ARR minimum</p> <ul> <li>Dedicated support</li> <li>Co-marketing opportunities</li> <li>Training resources</li> <li>15% revenue share</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#gold-partner","title":"Gold Partner","text":"<p>$50K ARR minimum</p> <ul> <li>Priority support</li> <li>Joint solution development</li> <li>Marketing development funds</li> <li>18% revenue share</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#platinum-partner","title":"Platinum Partner","text":"<p>$250K ARR minimum</p> <ul> <li>Strategic partnership</li> <li>Custom solutions</li> <li>Executive sponsorship</li> <li>20% revenue share</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#implementation-timeline","title":"Implementation Timeline","text":"<p>Get up and running in 4 weeks with our proven implementation process.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#week-1-setup-configuration","title":"Week 1: Setup &amp; Configuration","text":"<p>Create account, configure database, set up development environment, and complete initial training.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#week-2-integration-development","title":"Week 2: Integration Development","text":"<p>Implement core integration, develop data models, set up pipelines, and begin testing.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#week-3-testing-optimization","title":"Week 3: Testing &amp; Optimization","text":"<p>Conduct performance testing, optimize queries, implement monitoring, and refine integration.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#week-4-production-deployment","title":"Week 4: Production Deployment","text":"<p>Deploy to production, configure monitoring and alerts, complete documentation, and begin support handoff.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#fraud-detection-application","title":"Fraud Detection Application","text":""},{"location":"ai-core/data/vector_search/datastax-astra-db/#real-time-fraud-detection-showcase","title":"Real-Time Fraud Detection Showcase","text":"<p>Enterprise-grade fraud detection powered by DataStax Astra DB's vector search and real-time analytics capabilities. Detect anomalies and prevent fraud at scale.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#application-stats","title":"Application Stats","text":"<ul> <li>Detection Latency: &lt;10ms</li> <li>Accuracy Rate: 99.7%</li> <li>Transactions/Day: 1M+</li> <li>Monitoring: 24/7 Real-Time</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#application-overview","title":"Application Overview","text":"<p>A production-ready fraud detection system leveraging DataStax Astra DB's distributed architecture and vector search capabilities.</p>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#real-time-transaction-monitoring","title":"Real-Time Transaction Monitoring","text":"<p>Monitor millions of transactions in real-time with sub-10ms latency.</p> <ul> <li>Instant transaction validation</li> <li>Pattern recognition using vector embeddings</li> <li>Behavioral anomaly detection</li> <li>Automated risk scoring</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#vector-based-similarity-search","title":"Vector-Based Similarity Search","text":"<p>Leverage Astra DB's vector search to identify fraudulent patterns.</p> <ul> <li>Transaction embedding generation</li> <li>Similarity-based fraud detection</li> <li>Historical pattern matching</li> <li>Adaptive learning from new fraud cases</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#scalable-architecture","title":"Scalable Architecture","text":"<p>Built on Astra DB's globally distributed, always-on infrastructure.</p> <ul> <li>Multi-region deployment</li> <li>Automatic scaling</li> <li>99.99% uptime SLA</li> <li>Zero-downtime updates</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#system-architecture","title":"System Architecture","text":"<p>Fraud Detection Pipeline:</p> <ol> <li>Transaction Ingestion - Real-time data streaming via Kafka/Event Streams</li> <li>Feature Extraction - Generate vector embeddings from transaction data</li> <li>Astra DB Query - Vector similarity search for fraud patterns</li> <li>Risk Scoring - ML model assigns fraud probability score</li> <li>Action &amp; Alert - Block transaction or trigger investigation</li> </ol>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#datastax-astra-db-advantages","title":"DataStax Astra DB Advantages","text":""},{"location":"ai-core/data/vector_search/datastax-astra-db/#ultra-low-latency","title":"Ultra-Low Latency","text":"<p>Sub-10ms query response times for real-time fraud detection.</p> <ul> <li>Distributed architecture for fast reads</li> <li>In-memory caching</li> <li>Optimized vector search</li> <li>Local data center routing</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#massive-scale","title":"Massive Scale","text":"<p>Handle millions of transactions per day with linear scalability.</p> <ul> <li>Horizontal scaling on demand</li> <li>Petabyte-scale storage</li> <li>No single point of failure</li> <li>Automatic load balancing</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#global-distribution","title":"Global Distribution","text":"<p>Deploy across multiple regions for compliance and performance.</p> <ul> <li>Multi-region replication</li> <li>Data sovereignty compliance</li> <li>Active-active architecture</li> <li>Disaster recovery built-in</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#vector-search-native","title":"Vector Search Native","text":"<p>Built-in vector search for AI-powered fraud detection.</p> <ul> <li>Native vector data type</li> <li>Approximate nearest neighbor (ANN)</li> <li>Hybrid search (vector + metadata)</li> <li>Real-time index updates</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#always-on-availability","title":"Always-On Availability","text":"<p>99.99% uptime SLA with automatic failover and recovery.</p> <ul> <li>Multi-datacenter replication</li> <li>Automatic node replacement</li> <li>Zero-downtime upgrades</li> <li>Continuous backups</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#cost-efficiency","title":"Cost Efficiency","text":"<p>Serverless pricing model - pay only for what you use.</p> <ul> <li>No infrastructure management</li> <li>Auto-scaling reduces costs</li> <li>Storage tiering options</li> <li>Predictable pricing</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#performance-metrics","title":"Performance Metrics","text":"<p>Real-world performance data from production deployments:</p> <ul> <li>Avg Query Latency: 8.5ms (\u2193 40% improvement)</li> <li>Transactions/Day: 2.5M (\u2191 150% growth)</li> <li>Detection Accuracy: 99.7% (\u2191 5% improvement)</li> <li>Fraud Prevented/Year: $2.1M (\u2191 180% increase)</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#implementation-example","title":"Implementation Example","text":"<pre><code>from astrapy import DataAPIClient\nfrom astrapy.constants import VectorMetric\nimport numpy as np\n\n# Initialize Astra DB client\nclient = DataAPIClient(token=\"YOUR_TOKEN\")\ndatabase = client.get_database(\"https://YOUR_DB_ID-YOUR_REGION.apps.astra.datastax.com\")\n\n# Create collection with vector search\ncollection = database.create_collection(\n    \"fraud_transactions\",\n    dimension=128,\n    metric=VectorMetric.COSINE\n)\n\n# Generate transaction embedding\ndef generate_embedding(transaction):\n    \"\"\"Convert transaction features to vector embedding\"\"\"\n    features = [\n        transaction['amount'],\n        transaction['merchant_category'],\n        transaction['time_of_day'],\n        transaction['location_distance'],\n        # ... more features\n    ]\n    # Use your ML model to generate embedding\n    embedding = model.encode(features)\n    return embedding.tolist()\n\n# Check for fraud in real-time\ndef check_fraud(transaction):\n    # Generate embedding for current transaction\n    embedding = generate_embedding(transaction)\n\n    # Search for similar historical fraud cases\n    results = collection.find(\n        sort={\"$vector\": embedding},\n        limit=10,\n        filter={\"is_fraud\": True}\n    )\n\n    # Calculate fraud risk score\n    fraud_scores = [r['fraud_score'] for r in results]\n    avg_similarity = np.mean([r['$similarity'] for r in results])\n\n    risk_score = avg_similarity * np.mean(fraud_scores)\n\n    # Store transaction with embedding\n    collection.insert_one({\n        \"transaction_id\": transaction['id'],\n        \"amount\": transaction['amount'],\n        \"merchant\": transaction['merchant'],\n        \"timestamp\": transaction['timestamp'],\n        \"$vector\": embedding,\n        \"risk_score\": risk_score,\n        \"is_fraud\": risk_score &gt; 0.85\n    })\n\n    return {\n        \"risk_score\": risk_score,\n        \"action\": \"block\" if risk_score &gt; 0.85 else \"allow\",\n        \"similar_cases\": len(results)\n    }\n\n# Example usage\ntransaction = {\n    \"id\": \"txn_12345\",\n    \"amount\": 5000.00,\n    \"merchant\": \"Electronics Store\",\n    \"merchant_category\": \"electronics\",\n    \"time_of_day\": 23,  # 11 PM\n    \"location_distance\": 500  # km from usual location\n}\n\nresult = check_fraud(transaction)\nprint(f\"Risk Score: {result['risk_score']:.2f}\")\nprint(f\"Action: {result['action']}\")\nprint(f\"Similar fraud cases found: {result['similar_cases']}\")\n</code></pre>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#fraud-detection-use-cases","title":"Fraud Detection Use Cases","text":""},{"location":"ai-core/data/vector_search/datastax-astra-db/#credit-card-fraud","title":"Credit Card Fraud","text":"<p>Detect unauthorized credit card transactions in real-time.</p> <ul> <li>Unusual spending patterns</li> <li>Geographic anomalies</li> <li>Merchant category mismatches</li> <li>Velocity checks</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#account-takeover-prevention","title":"Account Takeover Prevention","text":"<p>Identify and prevent unauthorized account access attempts.</p> <ul> <li>Login behavior analysis</li> <li>Device fingerprinting</li> <li>IP reputation scoring</li> <li>Session anomaly detection</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#payment-fraud-detection","title":"Payment Fraud Detection","text":"<p>Protect digital payment systems from fraudulent transactions.</p> <ul> <li>P2P transfer monitoring</li> <li>Chargeback prediction</li> <li>Money laundering detection</li> <li>Synthetic identity fraud</li> </ul>"},{"location":"ai-core/data/vector_search/datastax-astra-db/#insurance-fraud","title":"Insurance Fraud","text":"<p>Detect fraudulent insurance claims and applications.</p> <ul> <li>Claim pattern analysis</li> <li>Network fraud detection</li> <li>Duplicate claim identification</li> <li>Staged accident detection</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/","title":"OpenSearch","text":"<p>Open-source search and analytics engine with native vector search capabilities for AI applications.</p>"},{"location":"ai-core/data/vector_search/opensearch/#overview","title":"Overview","text":"<p>OpenSearch is a community-driven, open-source search and analytics suite that provides powerful vector search capabilities alongside traditional full-text search. Built on Apache Lucene, it offers enterprise-grade features for building intelligent AI applications.</p>"},{"location":"ai-core/data/vector_search/opensearch/#open-source-foundation","title":"Open Source Foundation","text":"<p>Community-driven development with enterprise support options.</p> <ul> <li>Apache 2.0 licensed</li> <li>Active community contributions</li> <li>Transparent development process</li> <li>No vendor lock-in</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#hybrid-search-capabilities","title":"Hybrid Search Capabilities","text":"<p>Combine vector similarity search with traditional keyword search.</p> <ul> <li>k-NN vector search</li> <li>Full-text search</li> <li>Hybrid scoring algorithms</li> <li>Filtered vector search</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#enterprise-features","title":"Enterprise Features","text":"<p>Production-ready features for mission-critical applications.</p> <ul> <li>Multi-tenancy support</li> <li>Fine-grained access control</li> <li>Audit logging</li> <li>Encryption at rest and in transit</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#key-features","title":"Key Features","text":""},{"location":"ai-core/data/vector_search/opensearch/#native-vector-search","title":"Native Vector Search","text":"<p>Built-in support for approximate nearest neighbor (ANN) search.</p> <ul> <li>HNSW (Hierarchical Navigable Small World) algorithm</li> <li>IVF (Inverted File) algorithm</li> <li>Product quantization for memory efficiency</li> <li>Real-time index updates</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#scalability-performance","title":"Scalability &amp; Performance","text":"<p>Distributed architecture for handling large-scale workloads.</p> <ul> <li>Horizontal scaling</li> <li>Shard-based distribution</li> <li>Query caching</li> <li>Index optimization</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#integration-ecosystem","title":"Integration Ecosystem","text":"<p>Rich ecosystem of plugins and integrations.</p> <ul> <li>Logstash for data ingestion</li> <li>Kibana/OpenSearch Dashboards for visualization</li> <li>Language clients (Python, Java, JavaScript, Go)</li> <li>AWS OpenSearch Service integration</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#common-integration-patterns","title":"Common Integration Patterns","text":""},{"location":"ai-core/data/vector_search/opensearch/#rag-applications","title":"RAG Applications","text":"<p>Power retrieval augmented generation with hybrid search.</p> <ul> <li>Document embedding storage</li> <li>Semantic + keyword search</li> <li>Context retrieval with filtering</li> <li>Multi-field search strategies</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#semantic-search","title":"Semantic Search","text":"<p>Implement intelligent search across documents and data.</p> <ul> <li>Vector similarity matching</li> <li>Metadata filtering</li> <li>Faceted search</li> <li>Relevance tuning</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#log-analytics-with-ai","title":"Log Analytics with AI","text":"<p>Combine traditional log analysis with AI-powered insights.</p> <ul> <li>Anomaly detection</li> <li>Pattern recognition</li> <li>Predictive analytics</li> <li>Real-time alerting</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#recommendation-systems","title":"Recommendation Systems","text":"<p>Build personalized recommendation engines.</p> <ul> <li>User behavior vectors</li> <li>Content similarity</li> <li>Collaborative filtering</li> <li>Real-time recommendations</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#deployment-options","title":"Deployment Options","text":""},{"location":"ai-core/data/vector_search/opensearch/#self-managed","title":"Self-Managed","text":"<p>Deploy on your own infrastructure for maximum control.</p> <ul> <li>On-premises deployment</li> <li>Cloud VMs (AWS, Azure, GCP)</li> <li>Kubernetes/OpenShift</li> <li>Docker containers</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#aws-opensearch-service","title":"AWS OpenSearch Service","text":"<p>Fully managed service on AWS.</p> <ul> <li>Automated provisioning</li> <li>Managed upgrades</li> <li>Built-in monitoring</li> <li>VPC integration</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#opensearch-cloud","title":"OpenSearch Cloud","text":"<p>Managed service from the OpenSearch project.</p> <ul> <li>Multi-cloud support</li> <li>Automated operations</li> <li>Enterprise support</li> <li>Global availability</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#use-cases","title":"Use Cases","text":""},{"location":"ai-core/data/vector_search/opensearch/#enterprise-search","title":"Enterprise Search","text":"<p>Build powerful search experiences across enterprise content.</p> <ul> <li>Document search</li> <li>Knowledge base search</li> <li>E-commerce product search</li> <li>Content discovery</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#observability-monitoring","title":"Observability &amp; Monitoring","text":"<p>Centralize logs, metrics, and traces for system observability.</p> <ul> <li>Log aggregation</li> <li>Metrics analysis</li> <li>Distributed tracing</li> <li>Performance monitoring</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#security-analytics","title":"Security Analytics","text":"<p>Detect and respond to security threats in real-time.</p> <ul> <li>SIEM capabilities</li> <li>Threat detection</li> <li>Compliance monitoring</li> <li>Incident response</li> </ul>"},{"location":"ai-core/data/vector_search/opensearch/#ai-powered-applications","title":"AI-Powered Applications","text":"<p>Enable intelligent features in your applications.</p> <ul> <li>Chatbots and virtual assistants</li> <li>Content recommendations</li> <li>Fraud detection</li> <li>Predictive maintenance</li> </ul>"},{"location":"ai-core/trust/","title":"Trust \u2013 AI Building Blocks","text":"<p>This resource helps you get started on designing, building, and deploying AI systems that are reliable, transparent, and compliant.</p> <p>Building trust in AI requires a holistic approach across the full AI lifecycle, from design and development to deployment and ongoing monitoring. This repository provides frameworks, best practices, and tools that can be applied to ensure your AI solutions are trusted and enterprise-ready. The Building Block of Trust includes:</p> <ul> <li>Design-Time Evaluations \u2013 Tools for evaluating AI models and agents in your development environment.</li> <li>Runtime Monitoring \u2013 Approaches for monitoring and validating AI behavior in production.  </li> <li>Compliance Accelerator \u2013 Streamline alignment with regulatory and industry standards.</li> </ul>"},{"location":"ai-core/trust/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Trusted AI building blocks repo</p>"},{"location":"ai-core/trust/compliance-accelerators/","title":"Compliance Accelerators","text":""},{"location":"ai-core/trust/compliance-accelerators/#why-this-matters","title":"Why This Matters","text":"<p>Building a high-quality, safe AI system is only half the challenge. Enterprises must also prove that their systems meet regulatory and industry standards \u2014 and they must do so continuously, not just at launch. The compliance accelerator bridges the gap between the technical work of AI engineering and the documentation demands of risk, legal, and compliance teams.</p> <p>For enterprise teams, this is critical because:</p> <ul> <li>Regulatory pressure is growing. The EU AI Act, NIST AI RMF, ISO 42001, and other frameworks impose concrete requirements on AI transparency, risk assessment, and human oversight. Non-compliance carries financial penalties and market access restrictions.</li> <li>Manual compliance is unsustainable. Assembling evaluation results, monitoring logs, and risk documentation by hand for every model \u2014 and keeping it current as models evolve \u2014 is slow, error-prone, and doesn't scale.</li> <li>Evidence already exists but isn't connected. Design-time evaluations produce quality metrics and factsheets. Runtime monitoring generates safety logs and drift records. The problem isn't a lack of evidence \u2014 it's that the evidence is scattered across tools and teams, and isn't mapped to the specific requirements that auditors need.</li> <li>Compliance is continuous, not one-time. Models change, data drifts, and regulations evolve. Organizations need a governance posture that stays current automatically rather than requiring periodic manual reassembly.</li> </ul>"},{"location":"ai-core/trust/compliance-accelerators/#ibm-watsonxgovernance-compliance-accelerator-overview","title":"IBM watsonx.governance Compliance Accelerator Overview","text":"<p>IBM watsonx.governance Compliance Accelerator is a Data-as-a-Service solution designed to support an organization\u2019s AI compliance efforts. It provides curated AI and model risk regulatory content through predefined Compliance Plans and associated Obligations. These plans group relevant requirements to address specific risks and clarify compliance expectations for model-based systems, including generative AI. The content is regularly updated to reflect changes in regulatory and industry frameworks.</p> <p>Key features include:</p> <ul> <li> <p>Clear guidance for model use case owners and compliance teams, including defined evidence requirements</p> </li> <li> <p>Regularly updated regulatory and framework content</p> </li> <li> <p>Coverage of major global frameworks, including the EU AI Act and the NIST AI RMF</p> </li> <li> <p>A preformatted data feed that can be directly imported into IBM watsonx.governance</p> </li> </ul> <p>For further information, including system prerequisites, technical specifications, enablement resources, and support options, please reach out to your IBM account representative.</p>"},{"location":"ai-core/trust/design-time-evaluations/","title":"Design-Time Evaluations","text":""},{"location":"ai-core/trust/design-time-evaluations/#why-this-matters-for-enterprises","title":"Why This Matters for Enterprises","text":"<p>AI systems that perform well in experimentation can fail unpredictably once they encounter real-world inputs, edge cases, and adversarial behavior. Design-time evaluations provide a structured way to measure quality, safety, and retrieval performance before deployment \u2014 catching issues when they are cheap to fix rather than after they've reached production.</p> <p>For enterprise teams, this is critical because:</p> <ul> <li> <p>Unvalidated systems fail at the edges. LLM pipelines can hallucinate under low-confidence retrieval, leak sensitive data through prompt injection, or degrade when upstream schemas change. Design-time evaluation surfaces these failure modes before release.</p> </li> <li> <p>Production failures are costly and difficult to debug. Issues like PII leakage, unsafe outputs, or ungrounded responses become significantly harder to diagnose once embedded in live workflows. Systematic pre-deployment testing reduces operational and incident response burden.</p> </li> <li> <p>Baselines are required for meaningful monitoring. The metrics captured at design time \u2014 accuracy, groundedness, retrieval quality, latency, cost \u2014 become the reference points for detecting drift and regression in production. Without a documented baseline, runtime monitoring lacks signal.</p> </li> <li> <p>Compliance requires testing. Regulatory frameworks such as the EU AI Act and the NIST AI RMF expect evidence of structured testing. Versioned datasets, reproducible scoring, and stored evaluation artifacts provide this audit trail as a byproduct of sound engineering practice.</p> </li> </ul> <p>Design-time evaluations integrate directly with IBM watsonx.governance to provide end-to-end traceability from development through governance review.</p>"},{"location":"ai-core/trust/design-time-evaluations/#architecture-overview","title":"Architecture Overview","text":"<p>The design-time evaluations capability consists of two independent Python packages that share a common integration layer with IBM watsonx services.</p> <pre><code>graph TD\n    subgraph app[\"Your AI Application\"]\n        PT[\"Prompt Templates\"]\n        AG[\"Your AI Agents\"]\n    end\n\n    subgraph prompt_eval[\"Prompt Evaluation\"]\n        SLM[\"SLM approach\"]\n        LLM[\"LLM-as-Judge approach\"]\n    end\n\n    subgraph agent_eval[\"Agent Evaluation\"]\n        BRAG[\"Basic RAG\"]\n        TC[\"Tool calling\"]\n        ARAG[\"Advanced multi-source RAG\"]\n    end\n\n    subgraph watsonx[\"IBM watsonx Services\"]\n        WAI[\"watsonx.ai&lt;br&gt;LLM inference&lt;br&gt;Model hosting\"]\n        WOS[\"watsonx.governance&lt;br&gt;Metric monitors&lt;br&gt;Subscriptions\"]\n        WXG[\"watsonx.governance&lt;br&gt;Factsheets&lt;br&gt;Experiment tracking\"]\n    end\n\n    PT --&gt; prompt_eval\n    AG --&gt; agent_eval\n    prompt_eval --&gt; watsonx\n    agent_eval --&gt; watsonx</code></pre> <p>Prompt evaluation supports two evaluation strategies:</p> <ul> <li>SLM (Small Language Model) \u2014 Leverages watsonx.governance's built-in smaller models for fast, cost-effective evaluation. Provides source attributions and works well for high-volume evaluation runs.</li> <li>LLM-as-Judge \u2014 Uses an external LLM for more nuanced analysis. Enables answer similarity scoring and more sophisticated quality judgments.</li> </ul> <p>Agent evaluation provides three specialized evaluators depending on the agent architecture:</p> <ul> <li>Basic RAG \u2014 For agents with simple retrieval-augmented generation over a local vector store.</li> <li>Tool Calling \u2014 For agents that invoke custom tools and functions.</li> <li>Advanced RAG \u2014 For multi-source RAG agents with intelligent routing across local documents and web search.</li> </ul> <p>Both packages produce structured metric results, support batch evaluation, and integrate with watsonx.governance for factsheet generation and experiment tracking.</p>"},{"location":"ai-core/trust/design-time-evaluations/#supported-metrics-reference","title":"Supported Metrics Reference","text":"<p>The metrics listed below are those demonstrated in the sample applications and notebooks included in the Trusted AI GitHub repository. The full set of metrics available through IBM watsonx.governance is more comprehensive \u2014 refer to the watsonx.governance documentation for the complete list.</p>"},{"location":"ai-core/trust/design-time-evaluations/#prompt-evaluation-metrics","title":"Prompt Evaluation Metrics","text":"Metric Category Description Available In Faithfulness Quality Measures whether the generated response is factually consistent with the provided context SLM, LLM-as-Judge Answer Relevance Quality Measures whether the response directly addresses the user's question SLM, LLM-as-Judge Answer Similarity Quality Measures semantic similarity between the generated response and ground truth LLM-as-Judge only ROUGE Score Quality Measures n-gram overlap between generated text and reference text SLM, LLM-as-Judge Context Relevance Retrieval Measures whether retrieved context passages are relevant to the query SLM, LLM-as-Judge Context Precision Retrieval Measures the proportion of retrieved passages that are relevant SLM, LLM-as-Judge Hit Rate Retrieval Measures whether at least one relevant passage was retrieved SLM, LLM-as-Judge NDCG Retrieval Measures ranking quality of retrieved passages (normalized discounted cumulative gain) SLM, LLM-as-Judge Average Precision Retrieval Measures precision across recall levels for retrieved passages SLM, LLM-as-Judge PII Detection Safety Detects personally identifiable information in model outputs SLM, LLM-as-Judge HAP Detection Safety Detects hate, abuse, and profanity in model outputs SLM, LLM-as-Judge Model Health Performance Tracks operational health of the model deployment SLM, LLM-as-Judge"},{"location":"ai-core/trust/design-time-evaluations/#agent-evaluation-metrics","title":"Agent Evaluation Metrics","text":"Metric Category Description Available In Context Relevance Quality Measures whether agent-retrieved context is relevant to the query BasicRAG, AdvancedRAG Faithfulness Quality Measures factual consistency of agent responses with retrieved context BasicRAG, AdvancedRAG Answer Similarity Quality Measures semantic similarity between agent response and ground truth BasicRAG, ToolCalling, AdvancedRAG Tool Call Accuracy Tool Measures whether the agent invoked the correct tools with appropriate parameters ToolCalling only Routing Accuracy Tool Measures whether the agent routed queries to the correct retrieval source AdvancedRAG only PII Detection Safety Detects personally identifiable information in agent outputs All (when enabled) HAP Detection Safety Detects hate, abuse, and profanity in agent outputs All (when enabled) HARM Detection Safety Detects harmful content in agent outputs All (when enabled) Latency Performance Tracks response time for agent interactions All Token Usage Performance Tracks token consumption per interaction All Cost Estimation Performance Estimates inference cost per interaction All"},{"location":"ai-core/trust/design-time-evaluations/#end-to-end-workflow","title":"End-to-End Workflow","text":""},{"location":"ai-core/trust/design-time-evaluations/#prompt-template-evaluation","title":"Prompt Template Evaluation","text":"<pre><code>graph TD\n    A[\"Prepare test data\"] --&gt; B[\"Choose approach&lt;br&gt;SLM or LLM-as-Judge\"]\n    B --&gt; C[\"Create evaluator\"]\n    C --&gt; D[\"Create prompt template&lt;br&gt;asset in watsonx\"]\n    D --&gt; E[\"Set up watsonx.governance monitoring\"]\n    E --&gt; F[\"Run evaluation&lt;br&gt;against test data\"]\n    F --&gt; G[\"Review metrics +&lt;br&gt;visualizations\"]\n    G --&gt; H[\"Inspect record-level results\"]\n    H --&gt; I[\"Generate factsheet\"]\n    I --&gt; J[(\"watsonx.governance\")]</code></pre> <ol> <li>Prepare test data. Create a CSV file with representative inputs, retrieved contexts, generated outputs, and ground truth answers.</li> <li>Choose an evaluation approach. Select SLM for fast, cost-effective evaluation or LLM-as-Judge for more nuanced analysis.</li> <li>Create the evaluator. Instantiate the evaluator with your chosen configuration.</li> <li>Create the prompt template asset. Register your prompt template in watsonx so it can be tracked and governed.</li> <li>Set up monitoring. Configure a watsonx.governance subscription to collect evaluation feedback.</li> <li>Run evaluation. Execute the evaluation against your test dataset and collect metric results.</li> <li>Review results. Examine aggregate metrics, visualizations, and record-level detail to identify areas for improvement.</li> <li>Generate a factsheet. Publish evaluation results to watsonx.governance as a governed artifact for compliance and audit readiness.</li> </ol>"},{"location":"ai-core/trust/design-time-evaluations/#agent-evaluation","title":"Agent Evaluation","text":"<pre><code>graph TD\n    A[\"Choose evaluator type&lt;br&gt;Basic RAG \u00b7 Tool Calling \u00b7 Advanced RAG\"] --&gt; B[\"Initialize evaluator&lt;br&gt;with config\"]\n    B --&gt; C[\"Build agent&lt;br&gt;Load documents or register tools\"]\n    C --&gt; D[\"Run single-query or&lt;br&gt;batch evaluation\"]\n    D --&gt; E[\"Retrieve metrics&lt;br&gt;as DataFrame\"]\n    E --&gt; F[\"Track experiment\"]\n    F --&gt; G[(\"watsonx.governance\")]\n    E --&gt; H[\"Compare results&lt;br&gt;across runs\"]</code></pre> <ol> <li>Choose the evaluator type. Select Basic RAG, Tool Calling, or Advanced RAG based on your agent's architecture.</li> <li>Initialize. Configure the evaluator with your watsonx credentials, evaluation parameters, and (if applicable) vector store and LLM settings.</li> <li>Build the agent. Load documents into the vector store (for RAG evaluators) or register tools (for the Tool Calling evaluator).</li> <li>Evaluate. Run a single query for quick validation or batch evaluation for comprehensive coverage.</li> <li>Analyze. Review the metrics DataFrame for quality, safety, and performance scores.</li> <li>Track. Log the experiment in watsonx.governance for traceability.</li> <li>Iterate. Compare results across multiple runs to measure the impact of prompt, model, or architecture changes.</li> </ol> <p>For full source code, working examples, setup instructions, and configuration details, visit the Trusted AI GitHub repository.</p>"},{"location":"ai-core/trust/run-time-monitoring/","title":"Run-time Monitoring","text":""},{"location":"ai-core/trust/run-time-monitoring/#why-this-matters","title":"Why This Matters","text":"<p>An AI system that passes every evaluation at design time can still fail in production. User behavior shifts, upstream data changes, and adversarial inputs introduce conditions that pre-deployment testing cannot fully anticipate. Runtime monitoring closes this gap by providing continuous observation and real-time safeguards for AI systems operating in the real world.</p> <p>For enterprise teams, this is critical because:</p> <ul> <li>Production failures are visible and costly. When a model generates harmful content, leaks PII, or returns irrelevant answers in front of customers, the impact is immediate \u2014 regulatory exposure, reputational damage, and loss of trust. Real-time guardrails provide the last line of defense before outputs reach users.</li> <li>Model quality degrades gradually. Drift in data distributions, shifts in user behavior, or changes to upstream systems can erode model performance over weeks or months. Without continuous measurement, teams discover degradation only after business metrics decline or customers complain.</li> <li>Compliance requires ongoing evidence. Regulatory frameworks don't just require pre-deployment testing \u2014 they expect organizations to demonstrate continuous monitoring and the ability to detect and respond to problems in production. Monitoring logs, drift alerts, and safety records serve as this operational evidence.</li> <li>Different AI modalities need different monitoring. Generative AI systems and traditional ML models have distinct failure modes. Generative AI can hallucinate, produce unsafe content, or drift in response quality. Traditional ML can drift in prediction accuracy, develop fairness issues, or degrade on new data distributions. Both need tailored monitoring approaches.</li> </ul> <p>Runtime monitoring integrates with IBM watsonx.governance to provide production-grade observability and safeguards.</p>"},{"location":"ai-core/trust/run-time-monitoring/#architecture-overview","title":"Architecture Overview","text":"<p>The runtime monitoring capability provides two independent layers \u2014 real-time guardrails for immediate protection and continuous monitoring for long-term observability. Each addresses a distinct use case and can be adopted independently.</p>"},{"location":"ai-core/trust/run-time-monitoring/#real-time-guardrails","title":"Real-Time Guardrails","text":"<p>Real-time guardrails evaluate every AI input and output against configurable safety and quality thresholds before responses reach users.</p> <pre><code>graph TD\n    REQ[\"User / Application Request\"]\n\n    subgraph guardrails[\"REAL-TIME GUARDRAILS\"]\n        direction TB\n        subgraph metrics_row[\" \"]\n            direction LR\n            CS[\"Content Safety&lt;br&gt;HAP, PII, Harm,&lt;br&gt;Jailbreak, Bias,&lt;br&gt;Violence, etc.\"]\n            RQ[\"RAG Quality&lt;br&gt;Answer relevance,&lt;br&gt;Context relevance,&lt;br&gt;Faithfulness\"]\n            RSQ[\"Response Quality&lt;br&gt;Completeness,&lt;br&gt;Conciseness,&lt;br&gt;Helpfulness,&lt;br&gt;Custom validators\"]\n        end\n        DEC{\"PASS / BLOCK&lt;br&gt;decision\"}\n    end\n\n    REQ --&gt; guardrails\n    CS --&gt; DEC\n    RQ --&gt; DEC\n    RSQ --&gt; DEC\n    DEC --&gt;|\"pass\"| RESP[\"Response delivered&lt;br&gt;to user\"]\n    DEC --&gt;|\"block\"| BLOCK[\"Response blocked&lt;br&gt;risk flagged\"]</code></pre>"},{"location":"ai-core/trust/run-time-monitoring/#continuous-monitoring","title":"Continuous Monitoring","text":"<p>Continuous monitoring tracks quality, drift, and fairness metrics over time across both generative AI and traditional ML workloads.</p> <pre><code>graph TD\n    subgraph continuous[\"CONTINUOUS MONITORING\"]\n        direction TB\n        subgraph mon_row[\" \"]\n            direction LR\n            GEN[\"Generative AI Monitoring&lt;br&gt;&lt;br&gt;Manual evaluation&lt;br&gt;Scheduled evaluation&lt;br&gt;Custom metrics&lt;br&gt;Interactive dashboard\"]\n            TRAD[\"Traditional AI Monitoring&lt;br&gt;&lt;br&gt;Model risk management&lt;br&gt;Fairness &amp; bias detection&lt;br&gt;Custom metrics &amp; monitors\"]\n        end\n        WOS[\"watsonx.governance&lt;br&gt;Subscriptions \u00b7 Monitors \u00b7 Feedback datasets \u00b7 Drift tracking\"]\n        WXG[\"watsonx.governance&lt;br&gt;Factsheets \u00b7 Audit records \u00b7 Governance artifacts\"]\n    end\n\n    GEN --&gt; WOS\n    TRAD --&gt; WOS\n    WOS --&gt; WXG</code></pre> <p>Real-time guardrails operate synchronously in the request path. Every input and output is scored against configurable thresholds. Content safety metrics use upper-limit thresholds (block when exceeded), RAG metrics use lower-limit thresholds (block when quality falls below), and response quality metrics use LLM-as-Judge or custom rule-based evaluation. Responses that violate thresholds are blocked before reaching the user.</p> <p>Continuous monitoring operates asynchronously, independent of the request path. Evaluation data is collected over time \u2014 either manually, on a schedule, or via streaming payloads \u2014 and fed into watsonx.governance for trend analysis, drift detection, and alerting. An interactive dashboard provides visualization of metrics, drift, and governance artifacts.</p>"},{"location":"ai-core/trust/run-time-monitoring/#supported-metrics-reference","title":"Supported Metrics Reference","text":"<p>The metrics listed below are those demonstrated in the sample applications and notebooks included in the Trusted AI GitHub repository. The full set of metrics available through IBM watsonx.governance is more comprehensive \u2014 refer to the watsonx.governance documentation for the complete list.</p>"},{"location":"ai-core/trust/run-time-monitoring/#real-time-guardrails-metrics","title":"Real-Time Guardrails Metrics","text":"Metric Category Description Threshold Type HAP Content Safety Hate, abuse, and profanity detection Upper-limit PII Content Safety Personally identifiable information detection Upper-limit Harm Content Safety General harm detection Upper-limit Violence Content Safety Violence-related content detection Upper-limit Profanity Content Safety Profanity detection Upper-limit Social Bias Content Safety Bias and stereotyping detection Upper-limit Jailbreak Content Safety Jailbreak attempt detection Upper-limit Unethical Behavior Content Safety Unethical content detection Upper-limit Sexual Content Content Safety Sexual content detection Upper-limit Evasiveness Content Safety Evasive or non-committal response detection Upper-limit Answer Relevance RAG Quality Whether the response addresses the user's question Lower-limit Context Relevance RAG Quality Whether retrieved passages are relevant to the query Lower-limit Faithfulness RAG Quality Whether the response is consistent with the provided context Lower-limit Answer Completeness Response Quality Whether the response fully addresses the question (LLM judge) LLM-as-Judge Conciseness Response Quality Whether the response avoids unnecessary verbosity (LLM judge) LLM-as-Judge Helpfulness Response Quality Whether the response is useful to the user (LLM judge) LLM-as-Judge Action-Oriented Validator Response Quality Custom rule-based check for actionable responses Rule-based"},{"location":"ai-core/trust/run-time-monitoring/#continuous-monitoring-metrics","title":"Continuous Monitoring Metrics","text":"Metric Category Applies To Description ROUGE Quality Generative AI N-gram overlap between generated and reference text Readability Quality Generative AI Text readability scores for generated outputs Drift (confidence) Drift Gen AI + Traditional Change in model confidence distributions over time Drift (prediction) Drift Gen AI + Traditional Shift in model prediction distributions Drift (metadata) Drift Gen AI + Traditional Changes in input feature distributions Model Health Performance Gen AI + Traditional Operational health of the model deployment Fairness Fairness Traditional AI Bias detection across protected attributes Indirect Bias Fairness Traditional AI Bias detected through proxy features Custom Metrics Custom Gen AI + Traditional User-defined metrics attached via watsonx.governance"},{"location":"ai-core/trust/run-time-monitoring/#metrics-by-use-case","title":"Metrics by Use Case","text":"Use Case Design-Time Baseline Runtime Monitoring Text Summarization ROUGE, SARI, readability, sentence similarity ROUGE/SARI drift, latency, PII/HAP violations Content Generation BLEU, METEOR, fluency, novelty BLEU degradation, safety violations, failed generations Question Answering F1, exact match, faithfulness, relevance F1/EM decline, hallucination rate, response time Entity Extraction Precision, recall, F1, span accuracy Accuracy drop, latency, PII leakage RAG Systems Retrieval recall@k, nDCG, faithfulness, ROUGE Retrieval drift, faithfulness decline, failed retrievals Code Generation CodeBLEU, syntax correctness, test pass rate Execution failures, unsafe patterns, hallucinated blocks"},{"location":"ai-core/trust/run-time-monitoring/#end-to-end-workflow","title":"End-to-End Workflow","text":""},{"location":"ai-core/trust/run-time-monitoring/#setting-up-real-time-guardrails","title":"Setting Up Real-Time Guardrails","text":"<pre><code>graph TD\n    A[\"Define safety thresholds&lt;br&gt;for each metric\"] --&gt; B[\"Start the guardrails&lt;br&gt;application\"]\n    B --&gt; C[\"Submit AI inputs/outputs&lt;br&gt;for evaluation\"]\n    C --&gt; D[\"Review pass/block&lt;br&gt;decisions + risk scores\"]\n    D --&gt; E[\"Tune thresholds based&lt;br&gt;on observed patterns\"]\n    E --&gt;|\"iterate\"| C</code></pre> <ol> <li>Set thresholds. Define acceptable limits for each content safety, RAG quality, and response quality metric based on your risk tolerance.</li> <li>Launch. Start the guardrails application and access the dashboard.</li> <li>Evaluate. Submit AI system inputs and outputs through the interface. Each interaction is scored against all configured metrics.</li> <li>Review. Inspect the color-coded risk dashboard. Red indicates high risk (threshold violated), green indicates acceptable output.</li> <li>Tune. Adjust thresholds based on observed patterns \u2014 tighten limits where the system is too permissive, relax where it is overly conservative.</li> </ol>"},{"location":"ai-core/trust/run-time-monitoring/#setting-up-continuous-monitoring","title":"Setting Up Continuous Monitoring","text":"<pre><code>graph TD\n    A[\"Manual evaluation&lt;br&gt;Establish baselines\"] --&gt; B[\"Create Prompt Template&lt;br&gt;Asset in watsonx\"]\n    B --&gt; C[\"Deploy runtime subscription&lt;br&gt;in watsonx.governance\"]\n    C --&gt; D[\"Score prompt inputs +&lt;br&gt;store feedback\"]\n    D --&gt; E[\"Create monitors +&lt;br&gt;plot baseline metrics\"]\n    E --&gt; F[\"Automated scheduled&lt;br&gt;evaluation\"]\n    F --&gt; G[\"Configure batch processing&lt;br&gt;+ scheduled runs\"]\n    G --&gt; H[\"Track drift, readability,&lt;br&gt;risk over time\"]\n    H --&gt; I[\"Custom metrics\"]\n    I --&gt; J[\"Define domain-specific&lt;br&gt;monitors\"]\n    J --&gt; K[\"Generate factsheets\"]\n    K --&gt; L[(\"watsonx.governance\")]\n    H --&gt;|\"drift detected\"| M[\"Feed back into&lt;br&gt;design-time evaluation\"]</code></pre> <ol> <li>Start with manual evaluation. Create a Prompt Template Asset, deploy a runtime subscription in watsonx.governance, score inputs from sample data, and establish baseline metrics.</li> <li>Automate evaluation. Configure batch processing and scheduled evaluation runs. Track ROUGE, readability, and risk metrics over time to detect drift.</li> <li>Add custom metrics. Define domain-specific monitors (e.g., user feedback scores, business-specific quality checks) and attach them to your deployment.</li> <li>Use the dashboard. Launch the interactive dashboard for visualization \u2014 manage prompts, run evaluations, monitor drift, and generate factsheets from a single interface.</li> <li>Close the loop. When monitoring detects degradation or drift, feed that signal back into the design-time evaluation phase. Re-evaluate, update, and re-deploy with full traceability.</li> </ol> <p>For full source code, notebooks, setup instructions, and configuration details, visit the Trusted AI GitHub repository.</p>"},{"location":"automation-core/","title":"Automation Core Capabilities","text":"<p>Automation capabilities empower organizations to design, operate, and continuously improve hybrid cloud environments with greater speed, consistency, and reliability. By integrating intelligent tooling, platform services, and operational workflows, enterprises can reduce manual intervention, minimize risk, and scale efficiently across dynamic infrastructures.</p> <p>Automation is no longer limited to deployment tasks --- it becomes a strategic enabler that drives operational stability, cost efficiency, performance assurance, and development agility. Through a structured automation approach, organizations can effectively build, observe, and optimize modern application ecosystems.</p>"},{"location":"automation-core/#automation-building-blocks","title":"Automation Building Blocks","text":"<p>To simplify adoption and ensure architectural alignment, automation is organized into three complementary building blocks:</p>"},{"location":"automation-core/#build-and-deploy","title":"Build and Deploy","text":"<p>Build and Deploy focuses on accelerating application delivery while maintaining consistency, security, and repeatability. This building block standardizes how infrastructure is provisioned, how applications are integrated, and how deployment workflows are executed.</p> <p>It enables organizations to:</p> <ul> <li>Automate infrastructure provisioning.</li> <li>Standardize application deployment.</li> <li>Simplify system integration.</li> <li>Strengthen identity and access controls.</li> <li>Improve developer productivity.</li> </ul> <p>Build and Deploy establishes the foundation for scalable DevOps and CI/CD practices.</p>"},{"location":"automation-core/#observe","title":"Observe","text":"<p>Observe centers on delivering deep operational visibility across applications, infrastructure, and networks. It transforms telemetry into actionable intelligence, enabling teams to detect anomalies early, accelerate troubleshooting, and maintain service reliability.</p> <p>It enables organizations to:</p> <ul> <li>Monitor application performance in real time.</li> <li>Analyze distributed system behavior.</li> <li>Identify performance bottlenecks.</li> <li>Detect anomalies proactively.</li> <li>Improve incident response efficiency.</li> </ul> <p>Observe ensures that dynamic environments remain transparent and manageable.</p>"},{"location":"automation-core/#optimize","title":"Optimize","text":"<p>Optimize emphasizes continuous improvement of efficiency, resilience, and resource utilization. It aligns financial intelligence, operational stability, and automated decision-making to ensure sustainable cloud operations.</p> <p>It enables organizations to:</p> <ul> <li>Improve cost efficiency.</li> <li>Strengthen resilience and compliance posture.</li> <li>Automate resource management.</li> <li>Prevent performance degradation.</li> <li>Balance cost-performance trade-offs.</li> </ul> <p>Optimize transforms operations into a closed-loop improvement model.</p>"},{"location":"automation-core/#unified-automation-strategy","title":"Unified Automation Strategy","text":"<p>Together, Build and Deploy, Observe, and Optimize create a cohesive automation framework. Each building block reinforces the others:</p> <ul> <li>Build establishes repeatability.</li> <li>Observe provides operational intelligence.</li> <li>Optimize drives continuous improvement</li> </ul> <p>This integrated model enables enterprises to scale hybrid cloud environments with greater predictability, stability, and efficiency.</p>"},{"location":"automation-core/build/","title":"Build and Deploy","text":"<p>Build and Deploy focuses on accelerating application delivery while ensuring consistency, security, and automation across environments. This building block enables organizations to standardize integration, identity, provisioning, and development workflows, reducing friction between development and operations. By combining platform services, automation frameworks, and AI-assisted tooling, enterprises can move from manual processes to repeatable, scalable delivery pipelines.</p> <ul> <li>Platform as a Service (iPaaS) Capabilities, delivered through IBM webMethods, simplify application and data integration across distributed systems.</li> <li>Authentication Management Enabled by IBM Verify, centralizes identity, access control, and security enforcement.</li> <li>Infrastructure as Code Powered by tools such as Terraform and Ansible, ensures consistent, automated environment provisioning.</li> <li>Code Assistant Supported by IBM Bob enhances developer productivity through AI-assisted code generation and modernization.</li> </ul>"},{"location":"automation-core/build/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Build - Automation Building Blocks repo.</p>"},{"location":"automation-core/build/#key-use-cases","title":"Key Use Cases","text":"<p>Platform as a Service (IBM webMethods) Organizations leverage this capability to integrate cloud and on-prem applications, orchestrate business workflows, enable API management, connect legacy systems, synchronize data across platforms, and streamline hybrid integration architectures.</p> <p>Authentication Management (IBM Verify) Typical scenarios include centralized identity and access management, single sign-on (SSO), multi-factor authentication (MFA), adaptive access policies, privileged access control, and securing application workloads across hybrid environments.</p> <p>Infrastructure as Code (Terraform, Ansible) Common use cases involve automated infrastructure provisioning, environment standardization, configuration management, deployment automation, drift prevention, multi-cloud orchestration, and repeatable DevOps pipelines.</p> <p>Code Assistant (IBM Bob) Organizations adopt this capability to accelerate code development, modernize legacy applications, generate automation scripts, assist with refactoring, improve developer efficiency, reduce manual coding effort, and support consistent implementation patterns.</p> <p>Together, these capabilities create a cohesive Build and Deploy model that enhances delivery speed, improves operational consistency, and embeds automation and security into the software lifecycle.</p>"},{"location":"automation-core/build/authentication-management/","title":"Authentication Management","text":""},{"location":"automation-core/build/authentication-management/#authentication-management-with-ibm-verify","title":"Authentication Management with IBM Verify","text":"<p>Authentication Management using IBM Verify delivers a unified, enterprise\u2011grade identity and access management solution that secures user access across cloud, hybrid, and on\u2011premises environments. IBM Verify centralizes authentication, access controls, and risk\u2011based decisions while enabling seamless, secure access to applications and services.</p>"},{"location":"automation-core/build/authentication-management/#why-it-matters","title":"Why It Matters","text":"<p>Identity has become the new security perimeter in modern enterprise architectures. Effective authentication management protects sensitive assets, ensures only authorized users gain access, and supports compliant, auditable access policies. IBM Verify enables organizations to balance strong security with user convenience through adaptive authentication and centralized control.</p>"},{"location":"automation-core/build/authentication-management/#challenges-addressed","title":"Challenges Addressed","text":"<p>IBM Verify helps solve key enterprise authentication challenges:</p> <ul> <li>Inconsistent authentication mechanisms.</li> <li>Credential compromise risks.</li> <li>Fragmented access policies.</li> <li>Poor user experience due to repeated logins.</li> <li>Compliance and audit complexity.</li> </ul>"},{"location":"automation-core/build/authentication-management/#capabilities-functions","title":"Capabilities &amp; Functions","text":"<ul> <li>Centralized Identity Verification Provides a unified authentication layer across workforce and consumer applications.</li> <li>Single Sign\u2011On (SSO) Enables users to authenticate once and securely access multiple applications.</li> <li>Multi\u2011Factor Authentication (MFA) Strengthens identity verification using multiple authentication factors.</li> <li>Adaptive &amp; Risk\u2011Based Access Adjusts authentication requirements dynamically based on contextual risk signals.</li> <li>Federation &amp; Standards Support Integrates with enterprise ecosystems using industry\u2011standard identity protocols.</li> <li>Lifecycle &amp; Policy Controls Ensures access is governed by identity lifecycle events and organizational policies.</li> </ul>"},{"location":"automation-core/build/authentication-management/#core-features","title":"Core Features","text":"<ul> <li>Centralized authentication and access policies\\</li> <li>Risk\u2011adaptive security controls\\</li> <li>Cloud\u2011native and hybrid deployment flexibility\\</li> <li>Identity federation support\\</li> <li>Audit and compliance reporting\\</li> <li>Seamless application integration</li> </ul>"},{"location":"automation-core/build/authentication-management/#typical-use-cases","title":"Typical Use Cases","text":"<p>Organizations commonly adopt IBM Verify to:</p> <ul> <li>Enable secure single sign\u2011on across enterprise applications.</li> <li>Enforce multi\u2011factor authentication.</li> <li>Support hybrid workforce access.</li> <li>Implement Zero Trust security models.</li> <li>Integrate SaaS and legacy systems.</li> <li>Improve regulatory compliance posture.</li> </ul>"},{"location":"automation-core/build/authentication-management/#business-outcomes","title":"Business Outcomes","text":"<p>Enterprises benefit through:</p> <ul> <li>Reduced unauthorized access risks.</li> <li>Improved user access experience.</li> <li>Stronger governance and policy consistency.</li> <li>Enhanced compliance readiness.</li> <li>Scalable hybrid identity integration</li> </ul>"},{"location":"automation-core/build/authentication-management/#summary","title":"Summary","text":"<p>IBM Verify transforms authentication management into a centralized, adaptive, and intelligence\u2011driven capability that strengthens enterprise security while preserving user productivity.</p>"},{"location":"automation-core/build/code-assistant/","title":"Code Assistant","text":""},{"location":"automation-core/build/code-assistant/#code-assistant-aipowered-developer-companion","title":"Code Assistant -- AI\u2011Powered Developer Companion","text":"<p>IBM's Code Assistant, commonly associated with Project Bob and watsonx Code Assistant, is an AI\u2011powered development assistant designed to augment modern software engineering workflows. Embedded directly within developer environments and IDEs, it provides contextual code generation, intelligent recommendations, automated refactoring, and real\u2011time quality insights. The assistant acts as a collaborative partner, improving both developer productivity and code reliability.</p>"},{"location":"automation-core/build/code-assistant/#business-value","title":"Business Value","text":"<p>Code Assistant enables organizations to accelerate software delivery while improving consistency and quality. It provides:</p> <ul> <li>Faster development cycles.</li> <li>Reduced manual coding effort.</li> <li>Improved developer efficiency.</li> <li>Early detection of defects and vulnerabilities.</li> <li>Standardized coding practices.</li> <li>Enhanced modernization capabilities</li> </ul> <p>This results in measurable gains in productivity, maintainability, and operational stability.</p>"},{"location":"automation-core/build/code-assistant/#developer-challenges-addressed","title":"Developer Challenges Addressed","text":"<ul> <li>Repetitive and boilerplate code creation.</li> <li>Fragmented development workflows.</li> <li>Slow debugging and issue resolution.</li> <li>Inconsistent code quality.</li> <li>Legacy application modernization complexity.</li> <li>Security vulnerabilities introduced during development.</li> </ul>"},{"location":"automation-core/build/code-assistant/#capabilities-functions","title":"Capabilities &amp; Functions","text":""},{"location":"automation-core/build/code-assistant/#aiassisted-code-generation","title":"AI\u2011Assisted Code Generation","text":"<ul> <li>Natural language driven code creation.</li> <li>Context\u2011aware code suggestions.</li> <li>Intelligent auto\u2011completion.</li> <li>Code explanation and comprehension.</li> </ul>"},{"location":"automation-core/build/code-assistant/#automated-development-workflows","title":"Automated Development Workflows","text":"<ul> <li>AI\u2011assisted refactoring.</li> <li>Unit test generation.</li> <li>Code transformation and modernization.</li> <li>Debugging assistance.</li> </ul>"},{"location":"automation-core/build/code-assistant/#security-quality-intelligence","title":"Security &amp; Quality Intelligence","text":"<ul> <li>Detection of vulnerabilities and secrets.</li> <li>Inline quality feedback.</li> <li>Proactive remediation guidance.</li> <li>Consistent implementation patterns.</li> </ul>"},{"location":"automation-core/build/code-assistant/#feature-highlights","title":"Feature Highlights","text":"<ul> <li>Conversational AI integrated within the IDE.</li> <li>Contextual awareness of codebase and dependencies.</li> <li>Support for multiple programming languages.</li> <li>Automated modernization assistance.</li> <li>Built\u2011in secure coding guidance.</li> <li>Enhanced developer decision support.</li> </ul>"},{"location":"automation-core/build/code-assistant/#example-use-cases","title":"Example Use Cases","text":"<p>Organizations commonly leverage Code Assistant to:</p> <ul> <li>Accelerate feature development.</li> <li>Reduce time spent on repetitive coding.</li> <li>Modernize legacy applications.</li> <li>Improve debugging efficiency.</li> <li>Generate unit tests automatically.</li> <li>Detect security issues earlier in development.</li> <li>Enforce consistent coding standards.</li> </ul>"},{"location":"automation-core/build/code-assistant/#developer-benefits","title":"Developer Benefits","text":"<p>Code Assistant improves developer workflows by:</p> <ul> <li>Reducing cognitive load.</li> <li>Minimizing context switching.</li> <li>Increasing coding velocity.</li> <li>Improving code quality.</li> <li>Enhancing knowledge transfer.</li> <li>Supporting scalable development practices.</li> </ul> <p>IBM Code Assistant ultimately transforms software development from a purely manual activity into an AI\u2011augmented engineering process.</p>"},{"location":"automation-core/build/infrastructure-as-code/","title":"Infrastructure as Code","text":""},{"location":"automation-core/build/infrastructure-as-code/#automating-enterprise-retail-application-deployment","title":"Automating Enterprise Retail Application Deployment","text":"<p>Modern enterprise environments demand automation that is repeatable, auditable, and scalable across both infrastructure and application layers. This architecture demonstrates a production-aligned automation model using Terraform for infrastructure provisioning and Ansible for application deployment and orchestration. The approach establishes a layered automation strategy aligned with DevOps, compliance, and multi-environment deployment practices.</p>"},{"location":"automation-core/build/infrastructure-as-code/#business-value","title":"Business Value","text":"<p>Cloud-native platforms introduce dynamic infrastructure lifecycles and distributed workloads. Enterprises must balance agility, stability, governance, and cost efficiency. A Terraform + Ansible automation model delivers:</p> <ul> <li>Consistent environment provisioning.</li> <li>Reduced manual intervention.</li> <li>Improved deployment reliability.</li> <li>Stronger governance and auditability.</li> <li>Seamless CI/CD integration.</li> </ul> <p>This separation of responsibilities enables scalable and predictable automation.</p>"},{"location":"automation-core/build/infrastructure-as-code/#automation-challenges-addressed","title":"Automation Challenges Addressed","text":"<ul> <li>Manual and error-prone infrastructure provisioning.</li> <li>Configuration drift across environments.</li> <li>Inconsistent application deployments.</li> <li>Difficulty replicating production setups.</li> <li>Limited operational standardization.</li> <li>Slow environment creation cycles.</li> </ul>"},{"location":"automation-core/build/infrastructure-as-code/#capabilities-functions","title":"Capabilities &amp; Functions","text":""},{"location":"automation-core/build/infrastructure-as-code/#terraform-infrastructure-as-code","title":"Terraform -- Infrastructure as Code","text":"<p>Terraform provides declarative infrastructure lifecycle management, enabling:</p> <ul> <li>VPC and networking creation.</li> <li>OpenShift cluster provisioning.</li> <li>IAM and security configuration.</li> <li>Environment replication.</li> <li>Drift detection and state management.</li> </ul> <p>Terraform is optimized for managing infrastructure state.</p>"},{"location":"automation-core/build/infrastructure-as-code/#ansible-configuration-orchestration","title":"Ansible -- Configuration &amp; Orchestration","text":"<p>Ansible provides procedural automation designed for:</p> <ul> <li>Application deployment.</li> <li>Platform configuration.</li> <li>Kubernetes/OpenShift resource management.</li> <li>Day-2 operational workflows.</li> <li>CI/CD pipeline execution.</li> </ul> <p>Ansible is optimized for managing application and configuration state.</p>"},{"location":"automation-core/build/infrastructure-as-code/#enterprise-automation-strategy","title":"Enterprise Automation Strategy","text":"<p>Layer                    Primary Tool   Objective</p> <p>Infrastructure           Terraform      Provision cloud &amp; cluster resources   Platform Configuration   Ansible        Configure namespaces, policies   Applications             Ansible        Deploy workloads &amp; services   Operations               Ansible        Continuous operational automation</p> <p>This layered strategy ensures clear separation of concerns.</p>"},{"location":"automation-core/build/infrastructure-as-code/#infrastructure-provisioning","title":"Infrastructure Provisioning","text":"<p>Terraform automates the creation of foundational components required to host enterprise workloads:</p> <ul> <li>Virtual Private Cloud (VPC)\\</li> <li>Networking and security controls\\</li> <li>OpenShift cluster\\</li> <li>Worker node pools</li> </ul> <p>Terraform's state-driven model ensures reproducibility, drift prevention, and auditable changes while minimizing operational risk.</p>"},{"location":"automation-core/build/infrastructure-as-code/#application-deployment","title":"Application Deployment","text":"<p>Ansible orchestrates the Retail application lifecycle, including:</p> <ul> <li>Namespace creation.</li> <li>Image build and registry push.</li> <li>Secret and credential management.</li> <li>PostgreSQL deployment.</li> <li>Backend and frontend services.</li> <li>Database schema initialization.</li> <li>Rolling restarts.</li> <li>Validation checks.</li> </ul> <p>This reflects common enterprise microservices deployment patterns.</p>"},{"location":"automation-core/build/infrastructure-as-code/#operational-benefits","title":"Operational Benefits","text":"<p>Enterprises gain:</p> <ul> <li>Idempotent deployments.</li> <li>Reduced manual intervention.</li> <li>Faster environment creation.</li> <li>Consistent platform configuration.</li> <li>Simplified Day-2 operations.</li> <li>Improved release reliability.</li> </ul>"},{"location":"automation-core/build/infrastructure-as-code/#summary","title":"Summary","text":"<p>This automation framework demonstrates how enterprises can standardize infrastructure provisioning, automate application deployments, reduce operational risk, and improve scalability while aligning with DevOps best practices.</p>"},{"location":"automation-core/build/ipaas/","title":"iPaaS","text":""},{"location":"automation-core/build/ipaas/#platform-as-a-service-ipaas","title":"Platform as a Service (iPaaS)","text":"<p>IBM webMethods Integration represents a comprehensive, cloud-native Integration Platform as a Service (iPaaS) designed to connect applications, systems, and data across distributed enterprise environments. It enables organizations to seamlessly integrate SaaS applications, on-premise systems, APIs, and events through a low-code, drag-and-drop development model. By supporting hybrid integration patterns, API management, B2B/EDI, and event-driven architectures, the platform simplifies complex integration landscapes.</p>"},{"location":"automation-core/build/ipaas/#business-value","title":"Business Value","text":"<p>Modern enterprises operate within heterogeneous IT ecosystems where business processes span multiple platforms, cloud providers, and legacy systems. IBM webMethods Integration provides:</p> <ul> <li>Accelerated integration development.</li> <li>Reduced dependency on custom code.</li> <li>Improved operational agility.</li> <li>Enhanced system interoperability.</li> <li>Scalable hybrid integration capabilities.</li> </ul> <p>This approach allows enterprises to innovate rapidly while maintaining architectural consistency and governance.</p>"},{"location":"automation-core/build/ipaas/#integration-challenges-addressed","title":"Integration Challenges Addressed","text":"<ul> <li>Fragmented application landscapes.</li> <li>Complex SaaS-to-legacy connectivity.</li> <li>Data silos across platforms.</li> <li>API sprawl and governance gaps.</li> <li>Manual and brittle integration workflows.</li> <li>Limited visibility into integration dependencies.</li> </ul>"},{"location":"automation-core/build/ipaas/#capabilities-functions","title":"Capabilities &amp; Functions","text":"<p>IBM webMethods Integration delivers a broad set of enterprise integration capabilities:</p> <ul> <li>Hybrid application integration.</li> <li>API lifecycle management.</li> <li>Event-driven integration.</li> <li>B2B / EDI integration.</li> <li>Data synchronization and orchestration.</li> <li>Prebuilt connectors and adapters</li> </ul> <p>With over 600 connectors, the platform accelerates connectivity across cloud services, enterprise systems, databases, and messaging frameworks.</p>"},{"location":"automation-core/build/ipaas/#key-features","title":"Key Features","text":"<ul> <li>Low-code, drag-and-drop interface.</li> <li>Cloud-native scalability.</li> <li>Extensive connector ecosystem.</li> <li>Centralized integration governance.</li> <li>API management and security controls.</li> <li>Support for synchronous and asynchronous patterns</li> </ul>"},{"location":"automation-core/build/ipaas/#example-scenarios","title":"Example Scenarios","text":"<p>Organizations commonly leverage IBM webMethods Integration to:</p> <ul> <li>Connect SaaS applications with core enterprise systems.</li> <li>Modernize legacy integration architectures.</li> <li>Expose and manage enterprise APIs.</li> <li>Orchestrate cross-platform business workflows.</li> <li>Enable event-driven business processes.</li> <li>Integrate B2B partner ecosystems.</li> <li>Synchronize distributed data sources</li> </ul>"},{"location":"automation-core/build/ipaas/#operational-benefits","title":"Operational Benefits","text":"<p>Enterprises gain:</p> <ul> <li>Faster integration development cycles.</li> <li>Reduced custom integration complexity.</li> <li>Improved system interoperability.</li> <li>Enhanced architectural governance.</li> <li>Scalable hybrid connectivity.</li> <li>Simplified API and event management.</li> </ul> <p>IBM webMethods Integration ultimately transforms enterprise integration from a fragmented technical challenge into a scalable, standardized platform capability.</p>"},{"location":"automation-core/observe/","title":"Observe Building Blocks","text":"<p>Observe focuses on delivering deep, real-time visibility into application behavior, infrastructure performance, and network health across hybrid and multi-cloud environments. It enables enterprises to detect anomalies early, accelerate troubleshooting, and maintain service reliability by transforming telemetry into actionable operational intelligence.</p> <p>The Building Block of Observe includes:</p> <ul> <li> <p>Application Observability -- enabled by Instana, provides     automated, full-stack observability with granular visibility into     applications, microservices, containers, and underlying     infrastructure. It continuously analyzes performance metrics,     traces, and dependencies to detect issues before they impact users.</p> </li> <li> <p>Network Performance -- powered by IBM SevOne, delivers     comprehensive monitoring and analytics across complex network     environments. It enables enterprises to understand traffic behavior,     identify performance degradation, and ensure network reliability at     scale.</p> </li> </ul>"},{"location":"automation-core/observe/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Observe -- Automation Building Blocks repo</p>"},{"location":"automation-core/observe/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Application Observability (Instana) \u2192 Organizations leverage     this capability to gain real-time visibility into application     performance, automatically detect anomalies, trace transactions     across microservices, accelerate root cause analysis, monitor     Kubernetes / OpenShift workloads, and reduce mean time to resolution     (MTTR).</p> </li> <li> <p>Network Performance (IBM SevOne) \u2192 Typical use cases include     end-to-end network visibility, proactive detection of network     bottlenecks, traffic flow analysis, capacity planning, performance     trend analysis, SLA monitoring, and ensuring reliability across     distributed enterprise networks.</p> </li> </ul> <p>Together, these building blocks establish a continuous observability model where application intelligence and network analytics work in tandem to improve operational stability, performance assurance, and incident response efficiency.</p>"},{"location":"automation-core/observe/application-observability/","title":"Application Observability","text":""},{"location":"automation-core/observe/application-observability/#application-observability-intelligent-visibility-for-modern-applications","title":"Application Observability -- Intelligent Visibility for Modern Applications","text":"<p>Application Observability provides deep, contextual visibility into application behavior, performance, and dependencies by analyzing metrics, traces, logs, and events. Unlike traditional monitoring, observability enables teams to understand why issues occur, not just what failed. It is foundational for managing distributed, cloud-native systems.</p>"},{"location":"automation-core/observe/application-observability/#operational-context","title":"Operational Context","text":"<p>Modern applications are composed of microservices, containers, APIs, and dynamic infrastructure. Failures rarely originate from a single component. Performance degradation, latency spikes, and cascading failures require end-to-end visibility that spans services, platforms, and dependencies.</p> <p>Application observability addresses this complexity by correlating telemetry across the entire application stack.</p>"},{"location":"automation-core/observe/application-observability/#why-it-matters","title":"Why It Matters","text":"<p>Without comprehensive observability, organizations face:</p> <ul> <li>Prolonged incident resolution cycles.</li> <li>Fragmented troubleshooting workflows.</li> <li>Hidden dependency failures.</li> <li>Limited visibility into user experience.</li> <li>Increased operational risk.</li> </ul> <p>Observability transforms reactive firefighting into proactive performance management.</p>"},{"location":"automation-core/observe/application-observability/#enterprise-challenges-solved","title":"Enterprise Challenges Solved","text":"<ul> <li>Lack of visibility across microservices.</li> <li>Difficulty tracing distributed transactions.</li> <li>Noise from excessive alerts.</li> <li>Blind spots in Kubernetes / OpenShift workloads.</li> <li>Slow root cause analysis (RCA).</li> <li>Uncertain performance bottlenecks.</li> </ul>"},{"location":"automation-core/observe/application-observability/#technology-enablement-instana","title":"Technology Enablement -- Instana","text":"<p>Application Observability is enabled by Instana, which delivers automated, real-time, full-stack observability. Instana continuously discovers application components, maps dependencies, and analyzes telemetry without requiring extensive manual instrumentation.</p> <p>The platform is designed for dynamic, containerized, and cloud-native environments.</p>"},{"location":"automation-core/observe/application-observability/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Automatic Discovery Instana automatically detects services, containers, APIs, and infrastructure components, eliminating manual configuration overhead.</li> <li>Distributed Tracing Provides end-to-end visibility into transactions across microservices, enabling rapid identification of latency sources and service failures.</li> <li>Real-Time Performance Analytics Continuously analyzes performance metrics to detect anomalies, degradations, and emerging issues.</li> <li>Dependency Mapping Builds dynamic service dependency graphs, allowing teams to understand application interactions and failure propagation paths.</li> <li>Contextual Alerting Reduces alert noise by correlating events and highlighting only actionable incidents.</li> </ul>"},{"location":"automation-core/observe/application-observability/#representative-use-cases","title":"Representative Use Cases","text":"<p>Organizations commonly leverage application observability to:</p> <ul> <li>Detect performance anomalies before user impact.</li> <li>Accelerate root cause analysis.</li> <li>Monitor microservices architectures.</li> <li>Troubleshoot Kubernetes / OpenShift workloads.</li> <li>Optimize application performance.</li> <li>Reduce mean time to resolution (MTTR).</li> <li>Improve release stability.</li> </ul>"},{"location":"automation-core/observe/application-observability/#operational-impact","title":"Operational Impact","text":"<p>Enterprises benefit through:</p> <ul> <li>Faster incident detection and resolution.</li> <li>Reduced operational noise.</li> <li>Improved system reliability.</li> <li>Enhanced developer productivity.</li> <li>Better user experience visibility.</li> <li>Proactive performance optimization.</li> </ul>"},{"location":"automation-core/observe/application-observability/#strategic-outcome","title":"Strategic Outcome","text":"<p>Application Observability transforms operational visibility into a strategic capability, enabling enterprises to maintain reliability, performance, and resilience in increasingly complex application ecosystems.</p>"},{"location":"automation-core/observe/network-performance/","title":"Network Performance","text":""},{"location":"automation-core/observe/network-performance/#network-performance-intelligent-visibility-for-modern-networks","title":"Network Performance -- Intelligent Visibility for Modern Networks","text":"<p>Network Performance monitoring provides deep visibility into the behavior, health, and efficiency of enterprise network infrastructures. It enables organizations to analyze traffic patterns, detect degradations, identify bottlenecks, and ensure consistent service delivery across complex, distributed environments.</p>"},{"location":"automation-core/observe/network-performance/#operational-context","title":"Operational Context","text":"<p>Modern enterprise networks span data centers, cloud providers, branch offices, remote users, and software-defined architectures. Performance issues can emerge from congestion, misconfigurations, capacity limitations, or unexpected traffic behavior. Traditional monitoring tools often lack the scale and analytics needed to manage these dynamic environments.</p> <p>Network performance intelligence provides the operational clarity required to maintain reliability and service quality.</p>"},{"location":"automation-core/observe/network-performance/#why-it-matters","title":"Why It Matters","text":"<p>Without comprehensive network visibility, enterprises face:</p> <ul> <li>Undetected performance degradation\\</li> <li>Prolonged troubleshooting cycles\\</li> <li>Limited capacity planning insights\\</li> <li>Increased SLA violations\\</li> <li>Reduced application reliability</li> </ul> <p>Network performance analytics transform reactive problem resolution into proactive performance assurance.</p>"},{"location":"automation-core/observe/network-performance/#enterprise-challenges-solved","title":"Enterprise Challenges Solved","text":"<ul> <li>Fragmented network monitoring tools\\</li> <li>Lack of end-to-end traffic visibility\\</li> <li>Difficulty diagnosing intermittent issues\\</li> <li>Limited insight into network utilization trends\\</li> <li>Poor correlation between network and application performance\\</li> <li>Scaling challenges in hybrid environments</li> </ul>"},{"location":"automation-core/observe/network-performance/#technology-enablement-ibm-sevone","title":"Technology Enablement -- IBM SevOne","text":"<p>Network Performance is enabled by IBM SevOne, which delivers scalable, high-fidelity monitoring and analytics across enterprise networks. SevOne collects, correlates, and analyzes telemetry from network devices, flows, and services, providing actionable insights into performance, utilization, and anomalies.</p> <p>The platform is designed for large-scale, heterogeneous network environments.</p>"},{"location":"automation-core/observe/network-performance/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Comprehensive Network Visibility Provides unified monitoring across multi-vendor devices, cloud networks, and hybrid infrastructures.</li> <li>Traffic &amp; Flow Analytics Analyzes traffic patterns to identify congestion, abnormal flows, and utilization inefficiencies.</li> <li>Performance &amp; Latency Monitoring Continuously tracks network health indicators including latency, packet loss, and throughput.</li> <li>Capacity &amp; Trend Analysis Enables predictive planning by identifying growth patterns and saturation risks.</li> <li>Anomaly Detection</li> <li>Identifies unexpected network behavior that may indicate performance or security issues.</li> </ul>"},{"location":"automation-core/observe/network-performance/#representative-use-cases","title":"Representative Use Cases","text":"<p>Organizations commonly leverage network performance monitoring to:</p> <ul> <li>Detect network bottlenecks before service impact\\</li> <li>Optimize network capacity and utilization\\</li> <li>Troubleshoot latency and packet loss issues\\</li> <li>Monitor SLA compliance\\</li> <li>Analyze traffic behavior across hybrid clouds\\</li> <li>Support network modernization initiatives\\</li> <li>Improve application performance correlation</li> </ul>"},{"location":"automation-core/observe/network-performance/#operational-impact","title":"Operational Impact","text":"<p>Enterprises benefit through:</p> <ul> <li>Faster issue detection and resolution\\</li> <li>Reduced operational downtime\\</li> <li>Improved network reliability\\</li> <li>Enhanced capacity planning\\</li> <li>Better visibility into traffic dynamics\\</li> <li>Proactive performance optimization</li> </ul>"},{"location":"automation-core/observe/network-performance/#strategic-outcome","title":"Strategic Outcome","text":"<p>Network Performance intelligence transforms network monitoring into a strategic operational capability, enabling enterprises to maintain stability, scalability, and service reliability across increasingly complex digital infrastructures.</p>"},{"location":"automation-core/optimize/","title":"Optimize Building Blocks","text":"<p>Optimize focuses on continuously improving cost efficiency, operational stability, and resource utilization across hybrid cloud environments. It brings together financial visibility, resilience automation, and intelligent resource management to ensure applications remain performant, compliant, and economically sustainable.</p> <p>The Building Block of Optimize includes:</p> <ul> <li>Automated Resilience &amp; Compliance \u2013 enabled by IBM Concert, delivers centralized visibility into application risk, vulnerabilities, and compliance posture. It strengthens governance and operational resilience by correlating security, configuration, and runtime insights. </li> <li>FinOps \u2013 powered by Aptio, provides financial transparency and cost intelligence, allowing organizations to understand, allocate, and optimize cloud investments with precision.</li> <li>Automated Resource Management \u2013 driven by IBM Turbonomic, ensures applications receive the right resources at the right time, preserving performance while preventing waste and overprovisioning. </li> </ul>"},{"location":"automation-core/optimize/#github-repository","title":"Github Repository","text":"<p>Code for these accelerators can be found in the Optimize building blocks repo</p>"},{"location":"automation-core/optimize/#use-cases","title":"Use Cases","text":"<ul> <li>Automated Resilience &amp; Compliance (IBM Concert) \u2192 Organizations leverage this capability to continuously monitor CVE exposure, detect compliance drift, manage certificate lifecycles, assess security posture, map dependency risks, and identify systemic resilience weaknesses before they affect business-critical workloads.  </li> <li>FinOps \u2192 Cost transparency across teams, budget forecasting, spend anomaly detection, granular cost allocation, unit economics analysis, ROI evaluation for cloud initiatives, and identifying optimization opportunities across multi-cloud environments.  </li> <li>Automated Resource Management \u2192 Typical scenarios involve real-time resource scaling, workload placement optimization, infrastructure bottleneck prevention, SLA protection, container density optimization, automated performance remediation, and balancing cost-performance trade-offs. </li> </ul> <p>Together, these building blocks establish a closed-loop optimization model where cost efficiency, resilience, and performance continuously inform and enhance one another.</p>"},{"location":"automation-core/optimize/automated-resilience/","title":"Automated Resilience & Compliance","text":""},{"location":"automation-core/optimize/automated-resilience/#automated-resilience-compliance","title":"Automated Resilience &amp; Compliance","text":"<p>Automated Resilience &amp; Compliance focuses on continuously safeguarding application stability, security posture, and regulatory alignment across complex hybrid cloud environments. It provides enterprises with unified visibility into operational risks, vulnerabilities, and compliance deviations, enabling proactive rather than reactive management. This building block transforms resilience and governance from periodic audits into continuous, automated practices.</p>"},{"location":"automation-core/optimize/automated-resilience/#why-it-matters-for-enterprises","title":"Why It Matters for Enterprises","text":"<p>Modern enterprises operate highly distributed, containerized workloads where risks emerge dynamically --- from newly disclosed vulnerabilities to configuration drift and certificate expirations. Manual monitoring and fragmented tooling create blind spots, slow response times, and increased exposure. Continuous resilience and compliance automation reduces operational risk, strengthens governance, minimizes downtime, and supports regulatory obligations without introducing friction into delivery pipelines.</p>"},{"location":"automation-core/optimize/automated-resilience/#what-we-do-here","title":"What We Do Here","text":"<p>This building block centralizes resilience and compliance intelligence using platforms such as IBM Concert, correlating security, runtime, and configuration insights. It enables organizations to detect vulnerabilities, identify systemic weaknesses, evaluate compliance posture, and prioritize remediation actions based on risk impact. The emphasis is on creating actionable intelligence rather than simply generating alerts.</p>"},{"location":"automation-core/optimize/automated-resilience/#key-features-capabilities","title":"Key Features &amp; Capabilities","text":"<ul> <li>Unified visibility across applications, clusters, and environments.</li> <li>Continuous vulnerability and CVE exposure monitoring.</li> <li>Compliance posture tracking and drift detection.</li> <li>Certificate lifecycle and expiration management.</li> <li>Dependency and risk correlation across services.</li> <li>Risk-based prioritization and remediation guidance.</li> </ul>"},{"location":"automation-core/optimize/automated-resilience/#core-capabilities","title":"Core Capabilities","text":"<p>Automated Resilience &amp; Compliance delivers continuous risk intelligence by combining operational telemetry, vulnerability data, and governance signals. It helps enterprises understand not only what is wrong, but also why it matters and where to act first. By correlating application dependencies, infrastructure conditions, and security findings, it enables more accurate impact analysis and faster decision-making.</p>"},{"location":"automation-core/optimize/automated-resilience/#use-cases","title":"Use Cases","text":"<p>Organizations typically adopt this capability to:</p> <ul> <li>Continuously detect and assess CVE exposure across workloads.</li> <li>Identify compliance drift across Kubernetes / OpenShift     environments.</li> <li>Prevent outages caused by expired or mismanaged certificates.</li> <li>Map vulnerabilities to affected applications and business services.</li> <li>Prioritize remediation based on risk severity and blast radius.</li> <li>Improve audit readiness through continuous compliance tracking.</li> </ul>"},{"location":"automation-core/optimize/automated-resource-management/","title":"Automated Resource Management","text":""},{"location":"automation-core/optimize/automated-resource-management/#automated-resource-management","title":"Automated Resource Management","text":"<p>Automated Resource Management focuses on continuously optimizing application performance and infrastructure efficiency by dynamically aligning resource allocation with real-time demand. In modern hybrid and multi-cloud environments, where workloads are highly elastic and interdependent, this capability ensures that applications receive precisely the resources they require --- no more, no less. It transforms resource management from static provisioning into intelligent, automated decision-making.</p>"},{"location":"automation-core/optimize/automated-resource-management/#why-it-matters-for-enterprises","title":"Why It Matters for Enterprises","text":"<p>Enterprises frequently struggle with competing priorities: maintaining application performance while controlling infrastructure and cloud costs. Overprovisioning leads to wasted spend, while underprovisioning risks performance degradation and SLA violations. Manual tuning cannot keep pace with dynamic workloads. Automated resource management eliminates this trade-off by continuously balancing performance, utilization, and cost efficiency in real time.</p>"},{"location":"automation-core/optimize/automated-resource-management/#what-we-do-here","title":"What We Do Here","text":"<p>This building block leverages platforms such as IBM Turbonomic to analyze application demand, resource consumption patterns, and infrastructure constraints. It enables automated actions that optimize workload placement, scaling, and resourcing decisions. The objective is not simply monitoring utilization metrics, but actively ensuring that application performance objectives are met with optimal efficiency.</p>"},{"location":"automation-core/optimize/automated-resource-management/#key-features-capabilities","title":"Key Features &amp; Capabilities","text":"<ul> <li>Real-time demand-driven resource allocation.</li> <li>Intelligent workload placement and migration.</li> <li>Continuous performance assurance.</li> <li>Automated scaling and resourcing decisions.</li> <li>Infrastructure saturation and bottleneck prevention.</li> <li>Cost-performance optimization.</li> </ul>"},{"location":"automation-core/optimize/automated-resource-management/#core-capabilities","title":"Core Capabilities","text":"<p>Automated Resource Management delivers closed-loop automation by continuously analyzing telemetry across applications, containers, and infrastructure layers. It determines the most efficient resource actions required to maintain performance objectives. By understanding application dependencies and constraints, it avoids disruptive scaling behaviors and instead applies precise, context-aware optimizations.</p>"},{"location":"automation-core/optimize/automated-resource-management/#use-cases","title":"Use Cases","text":"<p>Organizations typically adopt this capability to:</p> <ul> <li>Prevent performance bottlenecks before user impact.</li> <li>Eliminate overprovisioning and reduce infrastructure waste.</li> <li>Optimize workload placement across clusters and clouds.</li> <li>Maintain SLA compliance under fluctuating demand.</li> <li>Improve container density and infrastructure utilization.</li> <li>Automate scaling decisions without manual intervention.</li> <li>Balance cost efficiency with performance requirements.</li> </ul>"},{"location":"automation-core/optimize/finops/","title":"FinOps","text":""},{"location":"automation-core/optimize/finops/#finops","title":"FinOps","text":"<p>FinOps (Financial Operations) establishes a data-driven discipline that enables organizations to manage, govern, and optimize cloud investments. As enterprises scale across hybrid and multi-cloud environments, financial visibility becomes as critical as performance monitoring. FinOps bridges finance, technology, and operations to create accountability, transparency, and continuous cost optimization.</p>"},{"location":"automation-core/optimize/finops/#business-value","title":"Business Value","text":"<p>Cloud consumption models introduce dynamic, usage-based spending patterns that traditional budgeting approaches cannot adequately control. FinOps provides enterprises with the mechanisms to align cloud expenditure with business priorities, ensuring that innovation velocity does not compromise financial discipline.</p>"},{"location":"automation-core/optimize/finops/#financial-challenges-addressed","title":"Financial Challenges Addressed","text":"<ul> <li>Lack of cost transparency across teams and applications.</li> <li>Unpredictable cloud spending and budget overruns.</li> <li>Difficulty attributing costs to business units or services.</li> <li>Inefficient resource utilization leading to waste.</li> <li>Limited insight into ROI for modernization initiatives.</li> </ul>"},{"location":"automation-core/optimize/finops/#capabilities-functions","title":"Capabilities &amp; Functions","text":"<p>FinOps capabilities, typically enabled through platforms such as Aptio, deliver:</p> <ul> <li>Granular cost allocation and chargeback models.</li> <li>Budget forecasting and spend planning.</li> <li>Cost anomaly detection and variance analysis.</li> <li>Unit economics and service cost modeling.</li> <li>Optimization opportunity identification.</li> <li>Financial governance and policy alignment.</li> </ul>"},{"location":"automation-core/optimize/finops/#decision-intelligence","title":"Decision Intelligence","text":"<p>FinOps transforms raw billing data into actionable financial intelligence. Instead of simply reporting cloud spend, it helps stakeholders understand:</p> <ul> <li>What is driving cost fluctuations.</li> <li>Which services or workloads generate the highest value.</li> <li>Where inefficiencies or waste are occurring.</li> <li>How architectural decisions impact financial outcomes.</li> </ul>"},{"location":"automation-core/optimize/finops/#example-scenarios","title":"Example Scenarios","text":"<p>Organizations commonly leverage FinOps to:</p> <ul> <li>Establish cost accountability across product teams.</li> <li>Optimize cloud commitments and reserved capacity.</li> <li>Evaluate modernization initiatives using cost-benefit analysis.</li> <li>Detect unexpected spend spikes before financial impact.</li> <li>Improve budgeting accuracy for dynamic workloads.</li> <li>Align cloud usage with business growth strategies.</li> </ul> <p>FinOps ultimately enables enterprises to treat cloud economics as a continuous optimization process rather than a retrospective financial exercise.</p>"},{"location":"ibm-bob/","title":"Customizing IBM Bob to work with the Building Blocks","text":"<p>IBM Bob custom modes allow developers to tailor Bob's behavior by combining reusable Building Blocks. Numerous modes are available to support work in these areas to address specific operational needs and development workflows.</p> <ul> <li>Builidng agents </li> <li>MCP creation and integration</li> <li>Vector Search &amp; Document Processing</li> <li>Data Engineering &amp; Knowledge Pipelines</li> <li>Application Observability &amp; Monitoring</li> <li>Security, Risk &amp; Trust Intelligence</li> </ul> <p>This composable approach enables teams to design highly contextual assistants optimized for specialized tasks and domain-specific scenarios.</p>"},{"location":"ibm-bob/#code-repositories","title":"Code Repositories","text":"<p>Instructions and related files for these custom modes can be found in their respective repository.</p>"},{"location":"ibm-bob/#agents-code-repository","title":"Agents Code Repository","text":"<ul> <li>Agent Builder: Bob uses wxo's ADK and documentation MCP servers to build custom agents.</li> <li>MCP Builder: Expands on the Agent Builder mode to build and deploy MCP servers on wxo.</li> <li>Domain Agent Builder: Bob builds a tool-augmented RAG agent for partner's custom specific domain.</li> </ul>"},{"location":"ibm-bob/#data","title":"Data","text":"<ul> <li>Data for AI: Specialized for data engineering, architecture, and data operations</li> <li>RAG Ingestion: Ingest IBM Cloud Object Storage (COS) into vector databases.</li> <li>RAG Retrieval: Retrieve from OpenSearch or Milvus.</li> <li>RAG Builder: IBM Bob: Intelligence for Vector Search and Document Processing.</li> </ul>"},{"location":"ibm-bob/#automation","title":"Automation","text":"<ul> <li>Application monitoring and observability expert: Connect Bob with the Instana MCP server.</li> <li>Automated Resilience &amp; Compliance: Unified Vulnerability and Certificate Intelligence via IBM Concert.</li> </ul>"}]}